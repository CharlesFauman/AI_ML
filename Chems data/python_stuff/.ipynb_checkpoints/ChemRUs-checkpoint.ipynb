{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import load_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_dataframe = pd.read_csv(\"../data/chemsdata.csv\", sep=',', index_col=0)\n",
    "train_y = (np.array(train_dataframe.iloc[:,-1]) + 1)/2\n",
    "train_matrix = pd.DataFrame.as_matrix(train_dataframe.iloc[:,:-1])\n",
    "#train_matrix = np.delete(train_matrix, list(range(300,450)), axis = 0) # 643\n",
    "#train_y = np.delete(train_y, list(range(300,450)), axis = 0)\n",
    "#train_matrix = normalize(train_matrix, axis=0, norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shuffle_permutation = np.random.permutation(len(train_y))\n",
    "\n",
    "train_y = train_y[shuffle_permutation]\n",
    "train_matrix = train_matrix[shuffle_permutation]\n",
    "\n",
    "num_train = int(np.floor((len(train_matrix)*.8)))\n",
    "num_validation = int(np.floor((len(train_matrix)*.2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.8199052132701422\n"
     ]
    }
   ],
   "source": [
    "dt = tree.DecisionTreeClassifier()\n",
    "dt.fit(train_matrix[0:num_train], train_y[0:num_train])\n",
    "print(dt.score(train_matrix[0:num_train], train_y[0:num_train]))\n",
    "print(dt.score(train_matrix[-num_validation:], train_y[-num_validation:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(train_matrix[num_train:])\n",
    "train_scaled = scaler.transform(train_matrix)\n",
    "\n",
    "pca = PCA()\n",
    "pca = pca.fit(train_scaled[num_train:])\n",
    "train_pca = pca.transform(train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8696682464454977\n",
      "0.8909952606635071\n"
     ]
    }
   ],
   "source": [
    "lda = LDA()\n",
    "lda = lda.fit(train_pca, train_y)\n",
    "print(lda.score(train_pca[0:num_train], train_y[0:num_train]))\n",
    "print(lda.score(train_pca[-num_validation:], train_y[-num_validation:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_123 (Dense)            (None, 3)                 126       \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 3)                 21        \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 175\n",
      "Trainable params: 175\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(3, activation='relu', input_shape = (train_pca.shape[1],)))\n",
    "model.add(Dense(6, activation='relu'))\n",
    "model.add(Dense(3, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 844 samples, validate on 211 samples\n",
      "Epoch 1/250\n",
      "844/844 [==============================] - 0s 34us/step - loss: 0.2505 - acc: 0.9242 - val_loss: 0.3066 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/250\n",
      "844/844 [==============================] - 0s 37us/step - loss: 0.2503 - acc: 0.9265 - val_loss: 0.3057 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/250\n",
      "844/844 [==============================] - 0s 32us/step - loss: 0.2501 - acc: 0.9277 - val_loss: 0.3061 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 4/250\n",
      "844/844 [==============================] - 0s 32us/step - loss: 0.2501 - acc: 0.9265 - val_loss: 0.3076 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 5/250\n",
      "844/844 [==============================] - 0s 33us/step - loss: 0.2500 - acc: 0.9265 - val_loss: 0.3077 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 6/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.2497 - acc: 0.9265 - val_loss: 0.3072 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 7/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.2495 - acc: 0.9265 - val_loss: 0.3076 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 8/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.2494 - acc: 0.9265 - val_loss: 0.3084 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 9/250\n",
      "844/844 [==============================] - 0s 31us/step - loss: 0.2491 - acc: 0.9254 - val_loss: 0.3082 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 10/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.2492 - acc: 0.9242 - val_loss: 0.3075 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 11/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.2492 - acc: 0.9242 - val_loss: 0.3068 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 12/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.2487 - acc: 0.9254 - val_loss: 0.3081 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 13/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.2486 - acc: 0.9242 - val_loss: 0.3085 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 14/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.2488 - acc: 0.9265 - val_loss: 0.3094 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 15/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.2485 - acc: 0.9265 - val_loss: 0.3094 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 16/250\n",
      "844/844 [==============================] - 0s 31us/step - loss: 0.2485 - acc: 0.9265 - val_loss: 0.3076 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 17/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.2484 - acc: 0.9277 - val_loss: 0.3081 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 18/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.2487 - acc: 0.9277 - val_loss: 0.3068 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 19/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.2481 - acc: 0.9277 - val_loss: 0.3072 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 20/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.2479 - acc: 0.9265 - val_loss: 0.3087 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 21/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.2478 - acc: 0.9265 - val_loss: 0.3092 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 22/250\n",
      "844/844 [==============================] - 0s 24us/step - loss: 0.2476 - acc: 0.9265 - val_loss: 0.3091 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 23/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.2475 - acc: 0.9265 - val_loss: 0.3095 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 24/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.2473 - acc: 0.9277 - val_loss: 0.3090 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 25/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.2475 - acc: 0.9277 - val_loss: 0.3089 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 26/250\n",
      "844/844 [==============================] - 0s 24us/step - loss: 0.2473 - acc: 0.9277 - val_loss: 0.3089 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 27/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.2471 - acc: 0.9289 - val_loss: 0.3095 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 28/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.2469 - acc: 0.9289 - val_loss: 0.3099 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 29/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.2471 - acc: 0.9289 - val_loss: 0.3093 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 30/250\n",
      "844/844 [==============================] - 0s 23us/step - loss: 0.2470 - acc: 0.9289 - val_loss: 0.3099 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 31/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.2468 - acc: 0.9289 - val_loss: 0.3099 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 32/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.2471 - acc: 0.9277 - val_loss: 0.3112 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 33/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.2466 - acc: 0.9265 - val_loss: 0.3102 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 34/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.2466 - acc: 0.9289 - val_loss: 0.3101 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 35/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.2465 - acc: 0.9289 - val_loss: 0.3103 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 36/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.2466 - acc: 0.9289 - val_loss: 0.3115 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 37/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.2464 - acc: 0.9289 - val_loss: 0.3100 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 38/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.2461 - acc: 0.9289 - val_loss: 0.3105 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 39/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.2460 - acc: 0.9289 - val_loss: 0.3115 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 40/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.2460 - acc: 0.9289 - val_loss: 0.3115 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 41/250\n",
      "844/844 [==============================] - 0s 24us/step - loss: 0.2458 - acc: 0.9289 - val_loss: 0.3113 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 42/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.2459 - acc: 0.9301 - val_loss: 0.3111 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 43/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.2457 - acc: 0.9289 - val_loss: 0.3127 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 44/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.2456 - acc: 0.9301 - val_loss: 0.3118 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 45/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.2456 - acc: 0.9289 - val_loss: 0.3120 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 46/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.2453 - acc: 0.9289 - val_loss: 0.3129 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 47/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.2452 - acc: 0.9301 - val_loss: 0.3124 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 48/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.2452 - acc: 0.9301 - val_loss: 0.3129 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 49/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.2451 - acc: 0.9301 - val_loss: 0.3136 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 50/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.2449 - acc: 0.9301 - val_loss: 0.3136 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 51/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.2450 - acc: 0.9301 - val_loss: 0.3138 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 52/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.2447 - acc: 0.9313 - val_loss: 0.3127 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 53/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.2447 - acc: 0.9301 - val_loss: 0.3126 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 54/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.2447 - acc: 0.9301 - val_loss: 0.3126 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 55/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.2446 - acc: 0.9301 - val_loss: 0.3125 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 56/250\n",
      "844/844 [==============================] - 0s 23us/step - loss: 0.2443 - acc: 0.9301 - val_loss: 0.3133 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 57/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.2444 - acc: 0.9313 - val_loss: 0.3140 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 58/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.2444 - acc: 0.9313 - val_loss: 0.3142 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 59/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.2447 - acc: 0.9313 - val_loss: 0.3147 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 60/250\n",
      "844/844 [==============================] - 0s 31us/step - loss: 0.2439 - acc: 0.9313 - val_loss: 0.3140 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 61/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.2439 - acc: 0.9301 - val_loss: 0.3139 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 62/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.2438 - acc: 0.9301 - val_loss: 0.3142 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 63/250\n",
      "844/844 [==============================] - 0s 23us/step - loss: 0.2437 - acc: 0.9301 - val_loss: 0.3148 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 64/250\n",
      "844/844 [==============================] - 0s 24us/step - loss: 0.2438 - acc: 0.9313 - val_loss: 0.3152 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 65/250\n",
      "844/844 [==============================] - 0s 31us/step - loss: 0.2438 - acc: 0.9313 - val_loss: 0.3160 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 66/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.2434 - acc: 0.9313 - val_loss: 0.3161 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 67/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.2433 - acc: 0.9313 - val_loss: 0.3159 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 68/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.2432 - acc: 0.9301 - val_loss: 0.3155 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 69/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.2433 - acc: 0.9325 - val_loss: 0.3160 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 70/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.2430 - acc: 0.9325 - val_loss: 0.3157 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 71/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.2429 - acc: 0.9325 - val_loss: 0.3162 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 72/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.2432 - acc: 0.9325 - val_loss: 0.3157 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 73/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.2425 - acc: 0.9313 - val_loss: 0.3157 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 74/250\n",
      "844/844 [==============================] - 0s 24us/step - loss: 0.2426 - acc: 0.9313 - val_loss: 0.3167 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 75/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.2428 - acc: 0.9313 - val_loss: 0.3174 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 76/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.2424 - acc: 0.9313 - val_loss: 0.3172 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 77/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.2426 - acc: 0.9313 - val_loss: 0.3174 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 78/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.2422 - acc: 0.9325 - val_loss: 0.3177 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 79/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.2426 - acc: 0.9325 - val_loss: 0.3177 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 80/250\n",
      "844/844 [==============================] - 0s 24us/step - loss: 0.2419 - acc: 0.9336 - val_loss: 0.3179 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 81/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.2415 - acc: 0.9336 - val_loss: 0.3180 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 82/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.2418 - acc: 0.9313 - val_loss: 0.3186 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 83/250\n",
      "844/844 [==============================] - 0s 37us/step - loss: 0.2418 - acc: 0.9301 - val_loss: 0.3187 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 84/250\n",
      "844/844 [==============================] - 0s 40us/step - loss: 0.2413 - acc: 0.9313 - val_loss: 0.3197 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 85/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.2412 - acc: 0.9313 - val_loss: 0.3201 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 86/250\n",
      "844/844 [==============================] - 0s 24us/step - loss: 0.2413 - acc: 0.9301 - val_loss: 0.3192 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 87/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.2410 - acc: 0.9336 - val_loss: 0.3200 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 88/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.2409 - acc: 0.9336 - val_loss: 0.3198 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 89/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.2409 - acc: 0.9336 - val_loss: 0.3201 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 90/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.2405 - acc: 0.9336 - val_loss: 0.3200 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 91/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.2405 - acc: 0.9336 - val_loss: 0.3208 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 92/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.2406 - acc: 0.9336 - val_loss: 0.3209 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 93/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.2404 - acc: 0.9325 - val_loss: 0.3211 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 94/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.2405 - acc: 0.9313 - val_loss: 0.3215 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 95/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.2410 - acc: 0.9313 - val_loss: 0.3223 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 96/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.2402 - acc: 0.9336 - val_loss: 0.3222 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 97/250\n",
      "844/844 [==============================] - 0s 23us/step - loss: 0.2399 - acc: 0.9336 - val_loss: 0.3212 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 98/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.2398 - acc: 0.9325 - val_loss: 0.3215 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 99/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.2397 - acc: 0.9325 - val_loss: 0.3222 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 100/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.2395 - acc: 0.9325 - val_loss: 0.3225 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 101/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.2395 - acc: 0.9336 - val_loss: 0.3227 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 102/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.2395 - acc: 0.9348 - val_loss: 0.3233 - val_acc: 0.8957\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 103/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.2396 - acc: 0.9348 - val_loss: 0.3236 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 104/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.2389 - acc: 0.9325 - val_loss: 0.3246 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 105/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.2396 - acc: 0.9348 - val_loss: 0.3241 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 106/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.2394 - acc: 0.9360 - val_loss: 0.3240 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 107/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.2389 - acc: 0.9360 - val_loss: 0.3242 - val_acc: 0.8957\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 108/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.2389 - acc: 0.9348 - val_loss: 0.3241 - val_acc: 0.8957\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 109/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.2387 - acc: 0.9348 - val_loss: 0.3242 - val_acc: 0.8957\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 110/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.2389 - acc: 0.9348 - val_loss: 0.3251 - val_acc: 0.8957\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 111/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.2388 - acc: 0.9348 - val_loss: 0.3237 - val_acc: 0.8957\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 112/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.2389 - acc: 0.9360 - val_loss: 0.3243 - val_acc: 0.8957\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 113/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.2387 - acc: 0.9360 - val_loss: 0.3249 - val_acc: 0.8957\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 114/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.2385 - acc: 0.9348 - val_loss: 0.3251 - val_acc: 0.8957\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 115/250\n",
      "844/844 [==============================] - 0s 32us/step - loss: 0.2382 - acc: 0.9360 - val_loss: 0.3249 - val_acc: 0.8957\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 116/250\n",
      "844/844 [==============================] - 0s 31us/step - loss: 0.2384 - acc: 0.9360 - val_loss: 0.3253 - val_acc: 0.8957\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 117/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.2381 - acc: 0.9360 - val_loss: 0.3255 - val_acc: 0.8957\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 118/250\n",
      "844/844 [==============================] - 0s 24us/step - loss: 0.2381 - acc: 0.9360 - val_loss: 0.3253 - val_acc: 0.8957\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 119/250\n",
      "844/844 [==============================] - 0s 31us/step - loss: 0.2382 - acc: 0.9348 - val_loss: 0.3248 - val_acc: 0.8957\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 120/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.2383 - acc: 0.9348 - val_loss: 0.3242 - val_acc: 0.8957\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 121/250\n",
      "844/844 [==============================] - 0s 31us/step - loss: 0.2379 - acc: 0.9348 - val_loss: 0.3247 - val_acc: 0.8957\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 122/250\n",
      "844/844 [==============================] - 0s 24us/step - loss: 0.2378 - acc: 0.9360 - val_loss: 0.3252 - val_acc: 0.8957\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 123/250\n",
      "844/844 [==============================] - 0s 24us/step - loss: 0.2378 - acc: 0.9360 - val_loss: 0.3255 - val_acc: 0.8957\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 124/250\n",
      "844/844 [==============================] - 0s 24us/step - loss: 0.2378 - acc: 0.9360 - val_loss: 0.3255 - val_acc: 0.8957\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 125/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.2375 - acc: 0.9348 - val_loss: 0.3254 - val_acc: 0.8957\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 126/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.2375 - acc: 0.9348 - val_loss: 0.3257 - val_acc: 0.8957\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 127/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.2377 - acc: 0.9348 - val_loss: 0.3258 - val_acc: 0.8957\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 128/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.2375 - acc: 0.9360 - val_loss: 0.3254 - val_acc: 0.8957\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 129/250\n",
      "844/844 [==============================] - 0s 24us/step - loss: 0.2374 - acc: 0.9348 - val_loss: 0.3255 - val_acc: 0.8957\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 130/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.2373 - acc: 0.9348 - val_loss: 0.3260 - val_acc: 0.8957\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 131/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.2374 - acc: 0.9348 - val_loss: 0.3270 - val_acc: 0.8957\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 132/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.2372 - acc: 0.9360 - val_loss: 0.3263 - val_acc: 0.8957\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 133/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.2376 - acc: 0.9360 - val_loss: 0.3257 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 134/250\n",
      "844/844 [==============================] - 0s 23us/step - loss: 0.2370 - acc: 0.9348 - val_loss: 0.3266 - val_acc: 0.8957\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 135/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.2373 - acc: 0.9360 - val_loss: 0.3263 - val_acc: 0.8957\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 136/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.2368 - acc: 0.9360 - val_loss: 0.3266 - val_acc: 0.8957\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 137/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.2369 - acc: 0.9348 - val_loss: 0.3261 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 138/250\n",
      "844/844 [==============================] - 0s 32us/step - loss: 0.2368 - acc: 0.9348 - val_loss: 0.3271 - val_acc: 0.8957\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 139/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.2367 - acc: 0.9360 - val_loss: 0.3268 - val_acc: 0.8957\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 140/250\n",
      "844/844 [==============================] - 0s 24us/step - loss: 0.2367 - acc: 0.9360 - val_loss: 0.3266 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 141/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.2370 - acc: 0.9360 - val_loss: 0.3267 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 142/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.2365 - acc: 0.9360 - val_loss: 0.3265 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 143/250\n",
      "844/844 [==============================] - 0s 24us/step - loss: 0.2364 - acc: 0.9360 - val_loss: 0.3265 - val_acc: 0.8957\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 144/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.2365 - acc: 0.9360 - val_loss: 0.3270 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 145/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.2363 - acc: 0.9360 - val_loss: 0.3270 - val_acc: 0.8957\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 146/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.2362 - acc: 0.9348 - val_loss: 0.3265 - val_acc: 0.8957\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 147/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.2361 - acc: 0.9348 - val_loss: 0.3272 - val_acc: 0.8957\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 148/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.2362 - acc: 0.9360 - val_loss: 0.3269 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 149/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.2360 - acc: 0.9360 - val_loss: 0.3270 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 150/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.2360 - acc: 0.9348 - val_loss: 0.3267 - val_acc: 0.8957\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 151/250\n",
      "844/844 [==============================] - 0s 24us/step - loss: 0.2359 - acc: 0.9360 - val_loss: 0.3266 - val_acc: 0.8957\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 152/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.2358 - acc: 0.9360 - val_loss: 0.3267 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 153/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.2358 - acc: 0.9360 - val_loss: 0.3270 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 154/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.2358 - acc: 0.9360 - val_loss: 0.3279 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 155/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.2358 - acc: 0.9360 - val_loss: 0.3281 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 156/250\n",
      "844/844 [==============================] - 0s 24us/step - loss: 0.2356 - acc: 0.9360 - val_loss: 0.3275 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 157/250\n",
      "844/844 [==============================] - 0s 24us/step - loss: 0.2358 - acc: 0.9360 - val_loss: 0.3284 - val_acc: 0.8957\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 158/250\n",
      "844/844 [==============================] - 0s 24us/step - loss: 0.2355 - acc: 0.9348 - val_loss: 0.3284 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 159/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.2354 - acc: 0.9348 - val_loss: 0.3284 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 160/250\n",
      "844/844 [==============================] - ETA: 0s - loss: 0.3017 - acc: 0.9250\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - 0s 24us/step - loss: 0.2353 - acc: 0.9348 - val_loss: 0.3280 - val_acc: 0.8910\n",
      "Epoch 161/250\n",
      "844/844 [==============================] - 0s 24us/step - loss: 0.2353 - acc: 0.9360 - val_loss: 0.3284 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 162/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.2354 - acc: 0.9336 - val_loss: 0.3288 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 163/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.2354 - acc: 0.9336 - val_loss: 0.3291 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 164/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.2350 - acc: 0.9336 - val_loss: 0.3285 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 165/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.2350 - acc: 0.9360 - val_loss: 0.3281 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 166/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.2349 - acc: 0.9360 - val_loss: 0.3286 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 167/250\n",
      "844/844 [==============================] - 0s 32us/step - loss: 0.2349 - acc: 0.9360 - val_loss: 0.3295 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 168/250\n",
      "844/844 [==============================] - 0s 37us/step - loss: 0.2351 - acc: 0.9348 - val_loss: 0.3298 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 169/250\n",
      "844/844 [==============================] - 0s 37us/step - loss: 0.2346 - acc: 0.9348 - val_loss: 0.3289 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 170/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.2348 - acc: 0.9360 - val_loss: 0.3291 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 171/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.2346 - acc: 0.9348 - val_loss: 0.3297 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 172/250\n",
      "844/844 [==============================] - 0s 24us/step - loss: 0.2346 - acc: 0.9360 - val_loss: 0.3299 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 173/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.2345 - acc: 0.9360 - val_loss: 0.3301 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 174/250\n",
      "844/844 [==============================] - 0s 23us/step - loss: 0.2344 - acc: 0.9360 - val_loss: 0.3304 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 175/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.2344 - acc: 0.9360 - val_loss: 0.3301 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 176/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.2344 - acc: 0.9360 - val_loss: 0.3306 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 177/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.2344 - acc: 0.9348 - val_loss: 0.3299 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 178/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.2340 - acc: 0.9360 - val_loss: 0.3303 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 179/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.2347 - acc: 0.9360 - val_loss: 0.3304 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 180/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.2341 - acc: 0.9348 - val_loss: 0.3308 - val_acc: 0.8957\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 181/250\n",
      "844/844 [==============================] - 0s 24us/step - loss: 0.2341 - acc: 0.9360 - val_loss: 0.3311 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 182/250\n",
      "844/844 [==============================] - ETA: 0s - loss: 0.3053 - acc: 0.9125\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - 0s 31us/step - loss: 0.2343 - acc: 0.9336 - val_loss: 0.3317 - val_acc: 0.8910\n",
      "Epoch 183/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.2338 - acc: 0.9348 - val_loss: 0.3314 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 184/250\n",
      "844/844 [==============================] - ETA: 0s - loss: 0.2254 - acc: 0.9375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - 0s 29us/step - loss: 0.2339 - acc: 0.9360 - val_loss: 0.3314 - val_acc: 0.8910\n",
      "Epoch 185/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.2337 - acc: 0.9372 - val_loss: 0.3315 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 186/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.2336 - acc: 0.9360 - val_loss: 0.3315 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 187/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.2336 - acc: 0.9360 - val_loss: 0.3318 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 188/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.2335 - acc: 0.9360 - val_loss: 0.3321 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 189/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.2335 - acc: 0.9360 - val_loss: 0.3326 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 190/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.2332 - acc: 0.9360 - val_loss: 0.3321 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 191/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.2333 - acc: 0.9360 - val_loss: 0.3320 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 192/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.2333 - acc: 0.9360 - val_loss: 0.3321 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 193/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.2334 - acc: 0.9360 - val_loss: 0.3328 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 194/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.2330 - acc: 0.9360 - val_loss: 0.3325 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 195/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.2329 - acc: 0.9348 - val_loss: 0.3328 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 196/250\n",
      "844/844 [==============================] - 0s 41us/step - loss: 0.2329 - acc: 0.9360 - val_loss: 0.3332 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 197/250\n",
      "844/844 [==============================] - 0s 33us/step - loss: 0.2328 - acc: 0.9360 - val_loss: 0.3339 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 198/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.2326 - acc: 0.9360 - val_loss: 0.3339 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 199/250\n",
      "844/844 [==============================] - 0s 31us/step - loss: 0.2327 - acc: 0.9360 - val_loss: 0.3342 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 200/250\n",
      "844/844 [==============================] - 0s 34us/step - loss: 0.2329 - acc: 0.9360 - val_loss: 0.3333 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 201/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.2325 - acc: 0.9372 - val_loss: 0.3341 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 202/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.2324 - acc: 0.9336 - val_loss: 0.3343 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 203/250\n",
      "844/844 [==============================] - 0s 32us/step - loss: 0.2324 - acc: 0.9348 - val_loss: 0.3340 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 204/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.2325 - acc: 0.9336 - val_loss: 0.3348 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 205/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.2323 - acc: 0.9360 - val_loss: 0.3351 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 206/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.2321 - acc: 0.9360 - val_loss: 0.3348 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 207/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.2320 - acc: 0.9348 - val_loss: 0.3352 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 208/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.2319 - acc: 0.9348 - val_loss: 0.3349 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 209/250\n",
      "844/844 [==============================] - 0s 33us/step - loss: 0.2321 - acc: 0.9348 - val_loss: 0.3346 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 210/250\n",
      "844/844 [==============================] - 0s 33us/step - loss: 0.2319 - acc: 0.9360 - val_loss: 0.3354 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 211/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.2318 - acc: 0.9360 - val_loss: 0.3356 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 212/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.2318 - acc: 0.9360 - val_loss: 0.3360 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 213/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.2319 - acc: 0.9360 - val_loss: 0.3373 - val_acc: 0.8863\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 214/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.2316 - acc: 0.9360 - val_loss: 0.3371 - val_acc: 0.8863\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 215/250\n",
      "844/844 [==============================] - 0s 31us/step - loss: 0.2316 - acc: 0.9372 - val_loss: 0.3368 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 216/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.2316 - acc: 0.9372 - val_loss: 0.3360 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 217/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.2316 - acc: 0.9360 - val_loss: 0.3359 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 218/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.2314 - acc: 0.9348 - val_loss: 0.3359 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 219/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.2312 - acc: 0.9348 - val_loss: 0.3365 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 220/250\n",
      "844/844 [==============================] - 0s 22us/step - loss: 0.2311 - acc: 0.9360 - val_loss: 0.3363 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 221/250\n",
      "844/844 [==============================] - 0s 32us/step - loss: 0.2310 - acc: 0.9372 - val_loss: 0.3365 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 222/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.2310 - acc: 0.9360 - val_loss: 0.3368 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 223/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.2311 - acc: 0.9348 - val_loss: 0.3377 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 224/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.2310 - acc: 0.9348 - val_loss: 0.3383 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 225/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.2307 - acc: 0.9348 - val_loss: 0.3384 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 226/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.2310 - acc: 0.9360 - val_loss: 0.3383 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 227/250\n",
      "844/844 [==============================] - 0s 31us/step - loss: 0.2308 - acc: 0.9360 - val_loss: 0.3382 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 228/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.2310 - acc: 0.9360 - val_loss: 0.3381 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 229/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.2306 - acc: 0.9372 - val_loss: 0.3388 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 230/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.2305 - acc: 0.9372 - val_loss: 0.3390 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 231/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.2307 - acc: 0.9360 - val_loss: 0.3389 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 232/250\n",
      "844/844 [==============================] - 0s 31us/step - loss: 0.2305 - acc: 0.9360 - val_loss: 0.3387 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 233/250\n",
      "844/844 [==============================] - ETA: 0s - loss: 0.1350 - acc: 0.9625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - 0s 25us/step - loss: 0.2302 - acc: 0.9360 - val_loss: 0.3386 - val_acc: 0.8910\n",
      "Epoch 234/250\n",
      "844/844 [==============================] - 0s 31us/step - loss: 0.2304 - acc: 0.9360 - val_loss: 0.3390 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 235/250\n",
      "844/844 [==============================] - 0s 24us/step - loss: 0.2302 - acc: 0.9360 - val_loss: 0.3393 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 236/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.2300 - acc: 0.9360 - val_loss: 0.3391 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 237/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.2299 - acc: 0.9372 - val_loss: 0.3391 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 238/250\n",
      "844/844 [==============================] - 0s 23us/step - loss: 0.2301 - acc: 0.9372 - val_loss: 0.3396 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 239/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.2299 - acc: 0.9372 - val_loss: 0.3393 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 240/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.2300 - acc: 0.9372 - val_loss: 0.3394 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 241/250\n",
      "844/844 [==============================] - 0s 31us/step - loss: 0.2297 - acc: 0.9372 - val_loss: 0.3394 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 242/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.2296 - acc: 0.9372 - val_loss: 0.3395 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 243/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.2298 - acc: 0.9360 - val_loss: 0.3404 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 244/250\n",
      "844/844 [==============================] - 0s 31us/step - loss: 0.2294 - acc: 0.9372 - val_loss: 0.3406 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 245/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.2295 - acc: 0.9384 - val_loss: 0.3415 - val_acc: 0.8863\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 246/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.2295 - acc: 0.9372 - val_loss: 0.3405 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 247/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.2297 - acc: 0.9372 - val_loss: 0.3408 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 248/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.2297 - acc: 0.9360 - val_loss: 0.3406 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 249/250\n",
      "844/844 [==============================] - 0s 36us/step - loss: 0.2293 - acc: 0.9384 - val_loss: 0.3404 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 250/250\n",
      "844/844 [==============================] - 0s 42us/step - loss: 0.2290 - acc: 0.9384 - val_loss: 0.3410 - val_acc: 0.8910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "211/211 [==============================] - 0s 53us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3409707786347629, 0.8909952632058853]"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_pca, train_y, epochs=250, batch_size=80, validation_split=.2)\n",
    "best_val = model.evaluate(train_pca[-num_validation:], train_y[-num_validation:])\n",
    "best_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 791 samples, validate on 264 samples\n",
      "Epoch 1/20\n",
      "791/791 [==============================] - 0s 19us/step - loss: 0.1519 - acc: 0.9558 - val_loss: 0.5183 - val_acc: 0.8977\n",
      "Epoch 2/20\n",
      "791/791 [==============================] - 0s 19us/step - loss: 0.1402 - acc: 0.9532 - val_loss: 0.5204 - val_acc: 0.8977\n",
      "Epoch 3/20\n",
      "791/791 [==============================] - 0s 24us/step - loss: 0.1570 - acc: 0.9545 - val_loss: 0.5212 - val_acc: 0.8977\n",
      "Epoch 4/20\n",
      "791/791 [==============================] - 0s 27us/step - loss: 0.1474 - acc: 0.9583 - val_loss: 0.5221 - val_acc: 0.9015\n",
      "Epoch 5/20\n",
      "791/791 [==============================] - 0s 28us/step - loss: 0.1500 - acc: 0.9494 - val_loss: 0.5230 - val_acc: 0.9015\n",
      "Epoch 6/20\n",
      "791/791 [==============================] - 0s 27us/step - loss: 0.1426 - acc: 0.9558 - val_loss: 0.5228 - val_acc: 0.9015\n",
      "Epoch 7/20\n",
      "791/791 [==============================] - 0s 24us/step - loss: 0.1491 - acc: 0.9621 - val_loss: 0.5232 - val_acc: 0.9015\n",
      "Epoch 8/20\n",
      "791/791 [==============================] - 0s 23us/step - loss: 0.1850 - acc: 0.9406 - val_loss: 0.5237 - val_acc: 0.9015\n",
      "Epoch 9/20\n",
      "791/791 [==============================] - 0s 23us/step - loss: 0.1590 - acc: 0.9570 - val_loss: 0.5247 - val_acc: 0.9015\n",
      "Epoch 10/20\n",
      "791/791 [==============================] - 0s 22us/step - loss: 0.1638 - acc: 0.9545 - val_loss: 0.5266 - val_acc: 0.8939\n",
      "Epoch 11/20\n",
      "791/791 [==============================] - 0s 22us/step - loss: 0.1730 - acc: 0.9494 - val_loss: 0.5293 - val_acc: 0.8902\n",
      "Epoch 12/20\n",
      "791/791 [==============================] - 0s 24us/step - loss: 0.1397 - acc: 0.9545 - val_loss: 0.5298 - val_acc: 0.8902\n",
      "Epoch 13/20\n",
      "791/791 [==============================] - 0s 23us/step - loss: 0.1284 - acc: 0.9633 - val_loss: 0.5306 - val_acc: 0.8902\n",
      "Epoch 14/20\n",
      "791/791 [==============================] - 0s 21us/step - loss: 0.1603 - acc: 0.9456 - val_loss: 0.5312 - val_acc: 0.8902\n",
      "Epoch 15/20\n",
      "791/791 [==============================] - 0s 22us/step - loss: 0.1436 - acc: 0.9570 - val_loss: 0.5305 - val_acc: 0.8902\n",
      "Epoch 16/20\n",
      "791/791 [==============================] - 0s 24us/step - loss: 0.1472 - acc: 0.9583 - val_loss: 0.5295 - val_acc: 0.8902\n",
      "Epoch 17/20\n",
      "791/791 [==============================] - 0s 28us/step - loss: 0.1587 - acc: 0.9456 - val_loss: 0.5294 - val_acc: 0.8902\n",
      "Epoch 18/20\n",
      "791/791 [==============================] - 0s 24us/step - loss: 0.1586 - acc: 0.9494 - val_loss: 0.5297 - val_acc: 0.8939\n",
      "Epoch 19/20\n",
      "791/791 [==============================] - 0s 26us/step - loss: 0.1534 - acc: 0.9482 - val_loss: 0.5306 - val_acc: 0.8939\n",
      "Epoch 20/20\n",
      "791/791 [==============================] - 0s 25us/step - loss: 0.1703 - acc: 0.9507 - val_loss: 0.5316 - val_acc: 0.8939\n",
      "211/211 [==============================] - 0s 90us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Train on 791 samples, validate on 264 samples\n",
      "Epoch 1/20\n",
      "791/791 [==============================] - 3s 4ms/step - loss: 0.1490 - acc: 0.9570 - val_loss: 0.5243 - val_acc: 0.8939\n",
      "Epoch 2/20\n",
      "791/791 [==============================] - 0s 27us/step - loss: 0.1613 - acc: 0.9494 - val_loss: 0.5268 - val_acc: 0.8939\n",
      "Epoch 3/20\n",
      "791/791 [==============================] - 0s 24us/step - loss: 0.1513 - acc: 0.9532 - val_loss: 0.5250 - val_acc: 0.8939\n",
      "Epoch 4/20\n",
      "791/791 [==============================] - 0s 22us/step - loss: 0.1628 - acc: 0.9494 - val_loss: 0.5217 - val_acc: 0.8939\n",
      "Epoch 5/20\n",
      "791/791 [==============================] - 0s 26us/step - loss: 0.1509 - acc: 0.9482 - val_loss: 0.5192 - val_acc: 0.9015\n",
      "Epoch 6/20\n",
      "791/791 [==============================] - 0s 23us/step - loss: 0.1552 - acc: 0.9532 - val_loss: 0.5184 - val_acc: 0.9015\n",
      "Epoch 7/20\n",
      "791/791 [==============================] - 0s 23us/step - loss: 0.1439 - acc: 0.9570 - val_loss: 0.5176 - val_acc: 0.9015\n",
      "Epoch 8/20\n",
      "791/791 [==============================] - 0s 25us/step - loss: 0.1782 - acc: 0.9558 - val_loss: 0.5168 - val_acc: 0.9015\n",
      "Epoch 9/20\n",
      "791/791 [==============================] - 0s 22us/step - loss: 0.1657 - acc: 0.9545 - val_loss: 0.5171 - val_acc: 0.8939\n",
      "Epoch 10/20\n",
      "791/791 [==============================] - 0s 19us/step - loss: 0.1494 - acc: 0.9507 - val_loss: 0.5173 - val_acc: 0.8977\n",
      "Epoch 11/20\n",
      "791/791 [==============================] - 0s 19us/step - loss: 0.1333 - acc: 0.9608 - val_loss: 0.5170 - val_acc: 0.8977\n",
      "Epoch 12/20\n",
      "791/791 [==============================] - 0s 17us/step - loss: 0.1280 - acc: 0.9633 - val_loss: 0.5178 - val_acc: 0.8977\n",
      "Epoch 13/20\n",
      "791/791 [==============================] - 0s 21us/step - loss: 0.1359 - acc: 0.9558 - val_loss: 0.5200 - val_acc: 0.8977\n",
      "Epoch 14/20\n",
      "791/791 [==============================] - 0s 23us/step - loss: 0.1414 - acc: 0.9633 - val_loss: 0.5229 - val_acc: 0.8977\n",
      "Epoch 15/20\n",
      "791/791 [==============================] - 0s 23us/step - loss: 0.1328 - acc: 0.9583 - val_loss: 0.5271 - val_acc: 0.9015\n",
      "Epoch 16/20\n",
      "791/791 [==============================] - 0s 20us/step - loss: 0.1349 - acc: 0.9595 - val_loss: 0.5305 - val_acc: 0.9015\n",
      "Epoch 17/20\n",
      "791/791 [==============================] - 0s 22us/step - loss: 0.1228 - acc: 0.9659 - val_loss: 0.5343 - val_acc: 0.8977\n",
      "Epoch 18/20\n",
      "791/791 [==============================] - 0s 20us/step - loss: 0.1490 - acc: 0.9532 - val_loss: 0.5382 - val_acc: 0.9015\n",
      "Epoch 19/20\n",
      "791/791 [==============================] - 0s 22us/step - loss: 0.1616 - acc: 0.9532 - val_loss: 0.5417 - val_acc: 0.9015\n",
      "Epoch 20/20\n",
      "791/791 [==============================] - 0s 21us/step - loss: 0.1488 - acc: 0.9456 - val_loss: 0.5446 - val_acc: 0.9015\n",
      "211/211 [==============================] - 0s 74us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Train on 791 samples, validate on 264 samples\n",
      "Epoch 1/20\n",
      "791/791 [==============================] - 3s 3ms/step - loss: 0.1594 - acc: 0.9494 - val_loss: 0.5185 - val_acc: 0.9015\n",
      "Epoch 2/20\n",
      "791/791 [==============================] - 0s 24us/step - loss: 0.1407 - acc: 0.9583 - val_loss: 0.5220 - val_acc: 0.8977\n",
      "Epoch 3/20\n",
      "791/791 [==============================] - 0s 21us/step - loss: 0.1448 - acc: 0.9507 - val_loss: 0.5282 - val_acc: 0.8939\n",
      "Epoch 4/20\n",
      "791/791 [==============================] - 0s 29us/step - loss: 0.1605 - acc: 0.9507 - val_loss: 0.5315 - val_acc: 0.8939\n",
      "Epoch 5/20\n",
      "791/791 [==============================] - 0s 23us/step - loss: 0.1551 - acc: 0.9545 - val_loss: 0.5336 - val_acc: 0.8902\n",
      "Epoch 6/20\n",
      "791/791 [==============================] - 0s 23us/step - loss: 0.1313 - acc: 0.9646 - val_loss: 0.5369 - val_acc: 0.8939\n",
      "Epoch 7/20\n",
      "791/791 [==============================] - 0s 24us/step - loss: 0.1302 - acc: 0.9659 - val_loss: 0.5403 - val_acc: 0.8902\n",
      "Epoch 8/20\n",
      "791/791 [==============================] - 0s 21us/step - loss: 0.1495 - acc: 0.9583 - val_loss: 0.5440 - val_acc: 0.8902\n",
      "Epoch 9/20\n",
      "791/791 [==============================] - 0s 21us/step - loss: 0.1671 - acc: 0.9520 - val_loss: 0.5468 - val_acc: 0.8939\n",
      "Epoch 10/20\n",
      "791/791 [==============================] - 0s 24us/step - loss: 0.1549 - acc: 0.9494 - val_loss: 0.5494 - val_acc: 0.8939\n",
      "Epoch 11/20\n",
      "791/791 [==============================] - 0s 21us/step - loss: 0.1525 - acc: 0.9532 - val_loss: 0.5538 - val_acc: 0.8939\n",
      "Epoch 12/20\n",
      "791/791 [==============================] - 0s 22us/step - loss: 0.1559 - acc: 0.9532 - val_loss: 0.5566 - val_acc: 0.8939\n",
      "Epoch 13/20\n",
      "791/791 [==============================] - 0s 24us/step - loss: 0.1545 - acc: 0.9558 - val_loss: 0.5604 - val_acc: 0.8864\n",
      "Epoch 14/20\n",
      "791/791 [==============================] - 0s 22us/step - loss: 0.1509 - acc: 0.9570 - val_loss: 0.5641 - val_acc: 0.8902\n",
      "Epoch 15/20\n",
      "791/791 [==============================] - 0s 22us/step - loss: 0.1494 - acc: 0.9494 - val_loss: 0.5674 - val_acc: 0.8902\n",
      "Epoch 16/20\n",
      "791/791 [==============================] - 0s 22us/step - loss: 0.1448 - acc: 0.9545 - val_loss: 0.5689 - val_acc: 0.8977\n",
      "Epoch 17/20\n",
      "791/791 [==============================] - 0s 23us/step - loss: 0.1551 - acc: 0.9520 - val_loss: 0.5700 - val_acc: 0.8977\n",
      "Epoch 18/20\n",
      "791/791 [==============================] - 0s 18us/step - loss: 0.1510 - acc: 0.9494 - val_loss: 0.5708 - val_acc: 0.8939\n",
      "Epoch 19/20\n",
      "791/791 [==============================] - 0s 19us/step - loss: 0.1377 - acc: 0.9621 - val_loss: 0.5714 - val_acc: 0.8939\n",
      "Epoch 20/20\n",
      "791/791 [==============================] - 0s 24us/step - loss: 0.1390 - acc: 0.9595 - val_loss: 0.5714 - val_acc: 0.8977\n",
      "211/211 [==============================] - 0s 86us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Train on 791 samples, validate on 264 samples\n",
      "Epoch 1/20\n",
      "791/791 [==============================] - 3s 3ms/step - loss: 0.1369 - acc: 0.9520 - val_loss: 0.5201 - val_acc: 0.9015\n",
      "Epoch 2/20\n",
      "791/791 [==============================] - 0s 23us/step - loss: 0.1452 - acc: 0.9583 - val_loss: 0.5316 - val_acc: 0.8939\n",
      "Epoch 3/20\n",
      "791/791 [==============================] - 0s 22us/step - loss: 0.1776 - acc: 0.9532 - val_loss: 0.5440 - val_acc: 0.8939\n",
      "Epoch 4/20\n",
      "791/791 [==============================] - 0s 26us/step - loss: 0.1589 - acc: 0.9545 - val_loss: 0.5526 - val_acc: 0.8939\n",
      "Epoch 5/20\n",
      "791/791 [==============================] - 0s 24us/step - loss: 0.1446 - acc: 0.9507 - val_loss: 0.5582 - val_acc: 0.8939\n",
      "Epoch 6/20\n",
      "791/791 [==============================] - 0s 23us/step - loss: 0.1637 - acc: 0.9545 - val_loss: 0.5616 - val_acc: 0.8939\n",
      "Epoch 7/20\n",
      "791/791 [==============================] - 0s 27us/step - loss: 0.1544 - acc: 0.9507 - val_loss: 0.5632 - val_acc: 0.8939\n",
      "Epoch 8/20\n",
      "791/791 [==============================] - 0s 22us/step - loss: 0.1527 - acc: 0.9507 - val_loss: 0.5643 - val_acc: 0.8939\n",
      "Epoch 9/20\n",
      "791/791 [==============================] - 0s 22us/step - loss: 0.1648 - acc: 0.9456 - val_loss: 0.5637 - val_acc: 0.8977\n",
      "Epoch 10/20\n",
      "791/791 [==============================] - 0s 22us/step - loss: 0.1627 - acc: 0.9494 - val_loss: 0.5615 - val_acc: 0.8977\n",
      "Epoch 11/20\n",
      "791/791 [==============================] - 0s 22us/step - loss: 0.1509 - acc: 0.9558 - val_loss: 0.5604 - val_acc: 0.8977\n",
      "Epoch 12/20\n",
      "791/791 [==============================] - 0s 25us/step - loss: 0.1526 - acc: 0.9608 - val_loss: 0.5603 - val_acc: 0.8977\n",
      "Epoch 13/20\n",
      "791/791 [==============================] - 0s 23us/step - loss: 0.1510 - acc: 0.9583 - val_loss: 0.5604 - val_acc: 0.8977\n",
      "Epoch 14/20\n",
      "791/791 [==============================] - 0s 23us/step - loss: 0.1477 - acc: 0.9570 - val_loss: 0.5609 - val_acc: 0.8977\n",
      "Epoch 15/20\n",
      "791/791 [==============================] - 0s 23us/step - loss: 0.1417 - acc: 0.9558 - val_loss: 0.5606 - val_acc: 0.8977\n",
      "Epoch 16/20\n",
      "791/791 [==============================] - 0s 20us/step - loss: 0.1512 - acc: 0.9482 - val_loss: 0.5621 - val_acc: 0.8977\n",
      "Epoch 17/20\n",
      "791/791 [==============================] - 0s 23us/step - loss: 0.1435 - acc: 0.9558 - val_loss: 0.5637 - val_acc: 0.8977\n",
      "Epoch 18/20\n",
      "791/791 [==============================] - 0s 20us/step - loss: 0.1353 - acc: 0.9608 - val_loss: 0.5653 - val_acc: 0.8939\n",
      "Epoch 19/20\n",
      "791/791 [==============================] - 0s 22us/step - loss: 0.1654 - acc: 0.9456 - val_loss: 0.5661 - val_acc: 0.8939\n",
      "Epoch 20/20\n",
      "791/791 [==============================] - 0s 23us/step - loss: 0.1439 - acc: 0.9608 - val_loss: 0.5664 - val_acc: 0.8977\n",
      "211/211 [==============================] - 0s 76us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Train on 791 samples, validate on 264 samples\n",
      "Epoch 1/20\n",
      "791/791 [==============================] - 3s 4ms/step - loss: 0.1320 - acc: 0.9545 - val_loss: 0.5234 - val_acc: 0.8977\n",
      "Epoch 2/20\n",
      "791/791 [==============================] - 0s 22us/step - loss: 0.1698 - acc: 0.9406 - val_loss: 0.5286 - val_acc: 0.8977\n",
      "Epoch 3/20\n",
      "791/791 [==============================] - 0s 20us/step - loss: 0.1537 - acc: 0.9595 - val_loss: 0.5290 - val_acc: 0.8977\n",
      "Epoch 4/20\n",
      "791/791 [==============================] - 0s 25us/step - loss: 0.1605 - acc: 0.9482 - val_loss: 0.5253 - val_acc: 0.8977\n",
      "Epoch 5/20\n",
      "791/791 [==============================] - 0s 20us/step - loss: 0.1626 - acc: 0.9507 - val_loss: 0.5235 - val_acc: 0.8977\n",
      "Epoch 6/20\n",
      "791/791 [==============================] - 0s 25us/step - loss: 0.1432 - acc: 0.9482 - val_loss: 0.5221 - val_acc: 0.9015\n",
      "Epoch 7/20\n",
      "791/791 [==============================] - 0s 20us/step - loss: 0.1280 - acc: 0.9633 - val_loss: 0.5212 - val_acc: 0.8977\n",
      "Epoch 8/20\n",
      "791/791 [==============================] - 0s 25us/step - loss: 0.1524 - acc: 0.9621 - val_loss: 0.5214 - val_acc: 0.9015\n",
      "Epoch 9/20\n",
      "791/791 [==============================] - 0s 22us/step - loss: 0.1350 - acc: 0.9659 - val_loss: 0.5222 - val_acc: 0.9015\n",
      "Epoch 10/20\n",
      "791/791 [==============================] - 0s 22us/step - loss: 0.1570 - acc: 0.9507 - val_loss: 0.5235 - val_acc: 0.9015\n",
      "Epoch 11/20\n",
      "791/791 [==============================] - 0s 22us/step - loss: 0.1448 - acc: 0.9595 - val_loss: 0.5245 - val_acc: 0.9015\n",
      "Epoch 12/20\n",
      "791/791 [==============================] - 0s 24us/step - loss: 0.1344 - acc: 0.9621 - val_loss: 0.5259 - val_acc: 0.9015\n",
      "Epoch 13/20\n",
      "791/791 [==============================] - 0s 22us/step - loss: 0.1533 - acc: 0.9507 - val_loss: 0.5262 - val_acc: 0.8977\n",
      "Epoch 14/20\n",
      "791/791 [==============================] - 0s 24us/step - loss: 0.1446 - acc: 0.9558 - val_loss: 0.5274 - val_acc: 0.8977\n",
      "Epoch 15/20\n",
      "791/791 [==============================] - 0s 21us/step - loss: 0.1766 - acc: 0.9418 - val_loss: 0.5274 - val_acc: 0.8977\n",
      "Epoch 16/20\n",
      "791/791 [==============================] - 0s 22us/step - loss: 0.1446 - acc: 0.9558 - val_loss: 0.5281 - val_acc: 0.8977\n",
      "Epoch 17/20\n",
      "791/791 [==============================] - 0s 20us/step - loss: 0.1379 - acc: 0.9583 - val_loss: 0.5289 - val_acc: 0.8977\n",
      "Epoch 18/20\n",
      "791/791 [==============================] - 0s 21us/step - loss: 0.1290 - acc: 0.9583 - val_loss: 0.5293 - val_acc: 0.9015\n",
      "Epoch 19/20\n",
      "791/791 [==============================] - 0s 23us/step - loss: 0.1454 - acc: 0.9583 - val_loss: 0.5296 - val_acc: 0.9015\n",
      "Epoch 20/20\n",
      "791/791 [==============================] - 0s 24us/step - loss: 0.1801 - acc: 0.9431 - val_loss: 0.5301 - val_acc: 0.9015\n",
      "211/211 [==============================] - 0s 76us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(5):\n",
    "    model_copy = keras.models.clone_model(model)\n",
    "    model_copy.set_weights(model.get_weights())\n",
    "    model.fit(train_pca, train_y, epochs=20, batch_size=1000, validation_split=.25)\n",
    "    val_score = model.evaluate(train_pca[-int(np.ceil((len(train_matrix)*.2))):], train_y[-int(np.ceil((len(train_matrix)*.2))):])[1]\n",
    "    if val_score < best_val:\n",
    "        model = model_copy\n",
    "        model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "    else:\n",
    "        best_val = val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(train_pca, to_categorical(train_y, num_classes = 2), epochs=1200, batch_size=80, validation_split=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 0s 43us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2846901022709941, 0.8862559227581838]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(train_pca[-num_validation:], train_y[-num_validation:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-20700356566b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_train_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'new_train' is not defined"
     ]
    }
   ],
   "source": [
    "model.evaluate(new_train, new_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_31 to have shape (1,) but got array with shape (2,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-a961ddb8f0fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_pca\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1002\u001b[0m                                    \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m                                    \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                    steps=steps)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1766\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1768\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1769\u001b[0m         \u001b[1;31m# Prepare inputs, delegate logic to `_test_loop`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1770\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m   1478\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1480\u001b[0;31m                                     exception_prefix='target')\n\u001b[0m\u001b[1;32m   1481\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1482\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    121\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_31 to have shape (1,) but got array with shape (2,)"
     ]
    }
   ],
   "source": [
    "model.evaluate(train_pca[-int(np.ceil((len(train_matrix)*.2))):], to_categorical(train_y[-int(np.ceil((len(train_matrix)*.2))):], num_classes = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1055/1055 [==============================] - 0s 38us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.7161996170242815, 0.8834123214839195]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(train_pca, to_categorical(train_y, num_classes = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(np.ceil((len(train_matrix)*.2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_dataframe = pd.read_csv(\"../data/chemstest.csv\", sep=',')\n",
    "test_matrix = pd.DataFrame.as_matrix(test_dataframe.iloc[:,:-1])\n",
    "test_pca = pca.transform(test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_predictions = model.predict_classes(test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "1\n",
      "-1\n",
      "1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "for num in test_predictions[:,0]:\n",
    "    print((num*2) - 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
