{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import load_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataframe = pd.read_csv(\"../data/chemsdata.csv\", sep=',', index_col=0)\n",
    "train_y = (np.array(train_dataframe.iloc[:,-1]) + 1)/2\n",
    "train_matrix = pd.DataFrame.as_matrix(train_dataframe.iloc[:,:-1])\n",
    "#train_matrix = np.delete(train_matrix, list(range(300,450)), axis = 0) # 643\n",
    "#train_y = np.delete(train_y, list(range(300,450)), axis = 0)\n",
    "#train_matrix = normalize(train_matrix, axis=0, norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_permutation = np.random.permutation(len(train_y))\n",
    "\n",
    "train_y = train_y[shuffle_permutation]\n",
    "train_matrix = train_matrix[shuffle_permutation]\n",
    "\n",
    "num_train = int(np.floor((len(train_matrix)*.8)))\n",
    "num_validation = int(np.floor((len(train_matrix)*.2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.8199052132701422\n"
     ]
    }
   ],
   "source": [
    "dt = tree.DecisionTreeClassifier()\n",
    "dt.fit(train_matrix[0:num_train], train_y[0:num_train])\n",
    "print(dt.score(train_matrix[0:num_train], train_y[0:num_train]))\n",
    "print(dt.score(train_matrix[-num_validation:], train_y[-num_validation:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(train_matrix[num_train:])\n",
    "train_scaled = scaler.transform(train_matrix)\n",
    "\n",
    "pca = PCA()\n",
    "pca = pca.fit(train_scaled[num_train:])\n",
    "train_pca = pca.transform(train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8696682464454977\n",
      "0.8909952606635071\n"
     ]
    }
   ],
   "source": [
    "lda = LDA()\n",
    "lda = lda.fit(train_pca, train_y)\n",
    "print(lda.score(train_pca[0:num_train], train_y[0:num_train]))\n",
    "print(lda.score(train_pca[-num_validation:], train_y[-num_validation:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_127 (Dense)            (None, 3)                 126       \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 3)                 21        \n",
      "_________________________________________________________________\n",
      "dense_130 (Dense)            (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 175\n",
      "Trainable params: 175\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(3, activation='relu', input_shape = (train_pca.shape[1],)))\n",
    "model.add(Dense(6, activation='relu'))\n",
    "model.add(Dense(3, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 844 samples, validate on 211 samples\n",
      "Epoch 1/250\n",
      "844/844 [==============================] - 0s 33us/step - loss: 0.1807 - acc: 0.9254 - val_loss: 0.4250 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.1811 - acc: 0.9254 - val_loss: 0.4239 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/250\n",
      "844/844 [==============================] - 0s 32us/step - loss: 0.1808 - acc: 0.9254 - val_loss: 0.4253 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 4/250\n",
      "844/844 [==============================] - 0s 35us/step - loss: 0.1811 - acc: 0.9242 - val_loss: 0.4244 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 5/250\n",
      "844/844 [==============================] - 0s 31us/step - loss: 0.1806 - acc: 0.9254 - val_loss: 0.4253 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 6/250\n",
      "844/844 [==============================] - 0s 31us/step - loss: 0.1808 - acc: 0.9254 - val_loss: 0.4261 - val_acc: 0.9005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 7/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.1809 - acc: 0.9265 - val_loss: 0.4230 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 8/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.1810 - acc: 0.9254 - val_loss: 0.4221 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 9/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.1804 - acc: 0.9254 - val_loss: 0.4253 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 10/250\n",
      "844/844 [==============================] - 0s 40us/step - loss: 0.1804 - acc: 0.9254 - val_loss: 0.4271 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 11/250\n",
      "844/844 [==============================] - 0s 31us/step - loss: 0.1804 - acc: 0.9265 - val_loss: 0.4249 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 12/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.1801 - acc: 0.9265 - val_loss: 0.4251 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 13/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.1804 - acc: 0.9254 - val_loss: 0.4268 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 14/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.1801 - acc: 0.9242 - val_loss: 0.4280 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 15/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.1803 - acc: 0.9254 - val_loss: 0.4268 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 16/250\n",
      "844/844 [==============================] - 0s 35us/step - loss: 0.1806 - acc: 0.9254 - val_loss: 0.4292 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 17/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.1800 - acc: 0.9254 - val_loss: 0.4273 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 18/250\n",
      "844/844 [==============================] - 0s 24us/step - loss: 0.1809 - acc: 0.9277 - val_loss: 0.4269 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 19/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.1796 - acc: 0.9277 - val_loss: 0.4273 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 20/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.1798 - acc: 0.9277 - val_loss: 0.4277 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 21/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.1800 - acc: 0.9265 - val_loss: 0.4288 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 22/250\n",
      "844/844 [==============================] - 0s 34us/step - loss: 0.1796 - acc: 0.9254 - val_loss: 0.4277 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 23/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.1797 - acc: 0.9301 - val_loss: 0.4270 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 24/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.1805 - acc: 0.9254 - val_loss: 0.4240 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 25/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.1799 - acc: 0.9277 - val_loss: 0.4266 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 26/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.1792 - acc: 0.9301 - val_loss: 0.4278 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 27/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.1795 - acc: 0.9289 - val_loss: 0.4292 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 28/250\n",
      "844/844 [==============================] - 0s 38us/step - loss: 0.1794 - acc: 0.9277 - val_loss: 0.4282 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 29/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.1794 - acc: 0.9289 - val_loss: 0.4296 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 30/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.1794 - acc: 0.9301 - val_loss: 0.4301 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 31/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.1795 - acc: 0.9289 - val_loss: 0.4287 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 32/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.1790 - acc: 0.9289 - val_loss: 0.4297 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 33/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.1786 - acc: 0.9277 - val_loss: 0.4309 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 34/250\n",
      "844/844 [==============================] - 0s 31us/step - loss: 0.1789 - acc: 0.9301 - val_loss: 0.4322 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 35/250\n",
      "844/844 [==============================] - 0s 32us/step - loss: 0.1787 - acc: 0.9254 - val_loss: 0.4318 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 36/250\n",
      "844/844 [==============================] - 0s 32us/step - loss: 0.1788 - acc: 0.9301 - val_loss: 0.4318 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 37/250\n",
      "844/844 [==============================] - 0s 32us/step - loss: 0.1782 - acc: 0.9277 - val_loss: 0.4324 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 38/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.1784 - acc: 0.9265 - val_loss: 0.4342 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 39/250\n",
      "844/844 [==============================] - 0s 31us/step - loss: 0.1784 - acc: 0.9265 - val_loss: 0.4321 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 40/250\n",
      "844/844 [==============================] - 0s 33us/step - loss: 0.1783 - acc: 0.9313 - val_loss: 0.4305 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 41/250\n",
      "844/844 [==============================] - 0s 34us/step - loss: 0.1783 - acc: 0.9301 - val_loss: 0.4309 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 42/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.1783 - acc: 0.9289 - val_loss: 0.4337 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 43/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.1783 - acc: 0.9313 - val_loss: 0.4329 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 44/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.1785 - acc: 0.9289 - val_loss: 0.4342 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 45/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.1783 - acc: 0.9277 - val_loss: 0.4323 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 46/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.1775 - acc: 0.9301 - val_loss: 0.4344 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 47/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.1778 - acc: 0.9301 - val_loss: 0.4347 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 48/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.1773 - acc: 0.9301 - val_loss: 0.4337 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 49/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.1779 - acc: 0.9277 - val_loss: 0.4341 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 50/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.1776 - acc: 0.9301 - val_loss: 0.4337 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 51/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.1773 - acc: 0.9301 - val_loss: 0.4338 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 52/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.1779 - acc: 0.9289 - val_loss: 0.4344 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 53/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.1771 - acc: 0.9301 - val_loss: 0.4359 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 54/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.1772 - acc: 0.9301 - val_loss: 0.4376 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 55/250\n",
      "844/844 [==============================] - 0s 31us/step - loss: 0.1768 - acc: 0.9301 - val_loss: 0.4337 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 56/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.1771 - acc: 0.9301 - val_loss: 0.4329 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 57/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.1770 - acc: 0.9325 - val_loss: 0.4338 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 58/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.1770 - acc: 0.9313 - val_loss: 0.4368 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 59/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.1767 - acc: 0.9313 - val_loss: 0.4357 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 60/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.1769 - acc: 0.9289 - val_loss: 0.4375 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 61/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.1767 - acc: 0.9313 - val_loss: 0.4371 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 62/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.1765 - acc: 0.9325 - val_loss: 0.4351 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 63/250\n",
      "844/844 [==============================] - 0s 24us/step - loss: 0.1771 - acc: 0.9325 - val_loss: 0.4372 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 64/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.1766 - acc: 0.9301 - val_loss: 0.4359 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 65/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.1768 - acc: 0.9325 - val_loss: 0.4372 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 66/250\n",
      "844/844 [==============================] - 0s 24us/step - loss: 0.1767 - acc: 0.9301 - val_loss: 0.4353 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 67/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.1764 - acc: 0.9301 - val_loss: 0.4341 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 68/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.1760 - acc: 0.9301 - val_loss: 0.4365 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 69/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.1763 - acc: 0.9289 - val_loss: 0.4383 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 70/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.1758 - acc: 0.9301 - val_loss: 0.4371 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 71/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.1763 - acc: 0.9325 - val_loss: 0.4385 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 72/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.1759 - acc: 0.9325 - val_loss: 0.4353 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 73/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.1762 - acc: 0.9325 - val_loss: 0.4377 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 74/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.1759 - acc: 0.9301 - val_loss: 0.4359 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 75/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.1764 - acc: 0.9289 - val_loss: 0.4365 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 76/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.1758 - acc: 0.9289 - val_loss: 0.4364 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 77/250\n",
      "844/844 [==============================] - 0s 24us/step - loss: 0.1759 - acc: 0.9325 - val_loss: 0.4404 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 78/250\n",
      "844/844 [==============================] - 0s 32us/step - loss: 0.1754 - acc: 0.9313 - val_loss: 0.4386 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 79/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.1757 - acc: 0.9325 - val_loss: 0.4400 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 80/250\n",
      "844/844 [==============================] - 0s 24us/step - loss: 0.1756 - acc: 0.9301 - val_loss: 0.4374 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 81/250\n",
      "844/844 [==============================] - 0s 24us/step - loss: 0.1755 - acc: 0.9301 - val_loss: 0.4374 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 82/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.1752 - acc: 0.9313 - val_loss: 0.4366 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 83/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.1764 - acc: 0.9289 - val_loss: 0.4377 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 84/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.1757 - acc: 0.9301 - val_loss: 0.4379 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 85/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.1753 - acc: 0.9301 - val_loss: 0.4385 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 86/250\n",
      "844/844 [==============================] - 0s 24us/step - loss: 0.1751 - acc: 0.9301 - val_loss: 0.4395 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 87/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.1755 - acc: 0.9301 - val_loss: 0.4394 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 88/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.1755 - acc: 0.9313 - val_loss: 0.4380 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 89/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.1752 - acc: 0.9301 - val_loss: 0.4372 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 90/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.1750 - acc: 0.9313 - val_loss: 0.4399 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 91/250\n",
      "844/844 [==============================] - 0s 23us/step - loss: 0.1751 - acc: 0.9301 - val_loss: 0.4388 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 92/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.1749 - acc: 0.9336 - val_loss: 0.4395 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 93/250\n",
      "844/844 [==============================] - 0s 24us/step - loss: 0.1750 - acc: 0.9325 - val_loss: 0.4409 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 94/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.1749 - acc: 0.9289 - val_loss: 0.4413 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 95/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.1746 - acc: 0.9325 - val_loss: 0.4412 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 96/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.1745 - acc: 0.9313 - val_loss: 0.4425 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 97/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.1750 - acc: 0.9325 - val_loss: 0.4404 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 98/250\n",
      "844/844 [==============================] - 0s 33us/step - loss: 0.1746 - acc: 0.9313 - val_loss: 0.4415 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 99/250\n",
      "844/844 [==============================] - 0s 24us/step - loss: 0.1745 - acc: 0.9313 - val_loss: 0.4415 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 100/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.1743 - acc: 0.9301 - val_loss: 0.4413 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 101/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.1746 - acc: 0.9325 - val_loss: 0.4432 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 102/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.1746 - acc: 0.9325 - val_loss: 0.4426 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 103/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.1745 - acc: 0.9277 - val_loss: 0.4412 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 104/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.1745 - acc: 0.9265 - val_loss: 0.4431 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 105/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.1747 - acc: 0.9301 - val_loss: 0.4439 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 106/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.1742 - acc: 0.9313 - val_loss: 0.4427 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 107/250\n",
      "844/844 [==============================] - 0s 23us/step - loss: 0.1741 - acc: 0.9301 - val_loss: 0.4408 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 108/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.1742 - acc: 0.9313 - val_loss: 0.4418 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 109/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.1745 - acc: 0.9301 - val_loss: 0.4439 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 110/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.1739 - acc: 0.9301 - val_loss: 0.4414 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 111/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.1742 - acc: 0.9313 - val_loss: 0.4394 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 112/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.1738 - acc: 0.9348 - val_loss: 0.4413 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 113/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.1741 - acc: 0.9313 - val_loss: 0.4421 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 114/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.1740 - acc: 0.9313 - val_loss: 0.4441 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 115/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.1740 - acc: 0.9301 - val_loss: 0.4413 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 116/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.1740 - acc: 0.9313 - val_loss: 0.4443 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 117/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.1740 - acc: 0.9289 - val_loss: 0.4429 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 118/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.1742 - acc: 0.9277 - val_loss: 0.4427 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 119/250\n",
      "844/844 [==============================] - 0s 24us/step - loss: 0.1741 - acc: 0.9289 - val_loss: 0.4426 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 120/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.1735 - acc: 0.9313 - val_loss: 0.4434 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 121/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.1736 - acc: 0.9301 - val_loss: 0.4433 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 122/250\n",
      "844/844 [==============================] - 0s 24us/step - loss: 0.1734 - acc: 0.9313 - val_loss: 0.4445 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 123/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.1739 - acc: 0.9325 - val_loss: 0.4441 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 124/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.1745 - acc: 0.9289 - val_loss: 0.4464 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 125/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.1740 - acc: 0.9289 - val_loss: 0.4448 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 126/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.1732 - acc: 0.9313 - val_loss: 0.4422 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 127/250\n",
      "844/844 [==============================] - 0s 38us/step - loss: 0.1735 - acc: 0.9301 - val_loss: 0.4426 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 128/250\n",
      "844/844 [==============================] - 0s 37us/step - loss: 0.1734 - acc: 0.9313 - val_loss: 0.4447 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 129/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.1739 - acc: 0.9301 - val_loss: 0.4447 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 130/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.1733 - acc: 0.9313 - val_loss: 0.4459 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 131/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.1733 - acc: 0.9313 - val_loss: 0.4433 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 132/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.1733 - acc: 0.9301 - val_loss: 0.4431 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 133/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.1732 - acc: 0.9313 - val_loss: 0.4447 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 134/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.1730 - acc: 0.9325 - val_loss: 0.4452 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 135/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.1733 - acc: 0.9313 - val_loss: 0.4480 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 136/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.1728 - acc: 0.9313 - val_loss: 0.4455 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 137/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.1728 - acc: 0.9313 - val_loss: 0.4452 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 138/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.1727 - acc: 0.9325 - val_loss: 0.4446 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 139/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.1725 - acc: 0.9325 - val_loss: 0.4457 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 140/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.1729 - acc: 0.9313 - val_loss: 0.4469 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 141/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.1725 - acc: 0.9313 - val_loss: 0.4480 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 142/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.1725 - acc: 0.9313 - val_loss: 0.4473 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 143/250\n",
      "844/844 [==============================] - 0s 33us/step - loss: 0.1726 - acc: 0.9325 - val_loss: 0.4462 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 144/250\n",
      "844/844 [==============================] - 0s 32us/step - loss: 0.1731 - acc: 0.9336 - val_loss: 0.4454 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 145/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.1726 - acc: 0.9336 - val_loss: 0.4474 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 146/250\n",
      "844/844 [==============================] - 0s 31us/step - loss: 0.1724 - acc: 0.9325 - val_loss: 0.4457 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 147/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.1723 - acc: 0.9313 - val_loss: 0.4446 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 148/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.1724 - acc: 0.9325 - val_loss: 0.4489 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 149/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.1723 - acc: 0.9301 - val_loss: 0.4485 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 150/250\n",
      "844/844 [==============================] - 0s 32us/step - loss: 0.1723 - acc: 0.9313 - val_loss: 0.4458 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 151/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.1720 - acc: 0.9325 - val_loss: 0.4480 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 152/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.1724 - acc: 0.9301 - val_loss: 0.4487 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 153/250\n",
      "844/844 [==============================] - 0s 24us/step - loss: 0.1724 - acc: 0.9301 - val_loss: 0.4478 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 154/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.1725 - acc: 0.9301 - val_loss: 0.4486 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 155/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.1715 - acc: 0.9313 - val_loss: 0.4486 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 156/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.1719 - acc: 0.9325 - val_loss: 0.4479 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 157/250\n",
      "844/844 [==============================] - 0s 24us/step - loss: 0.1719 - acc: 0.9336 - val_loss: 0.4483 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 158/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.1720 - acc: 0.9325 - val_loss: 0.4462 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 159/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.1719 - acc: 0.9313 - val_loss: 0.4485 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 160/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.1717 - acc: 0.9325 - val_loss: 0.4474 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 161/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.1717 - acc: 0.9336 - val_loss: 0.4485 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 162/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.1717 - acc: 0.9313 - val_loss: 0.4512 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 163/250\n",
      "844/844 [==============================] - 0s 23us/step - loss: 0.1719 - acc: 0.9313 - val_loss: 0.4499 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 164/250\n",
      "844/844 [==============================] - 0s 24us/step - loss: 0.1725 - acc: 0.9336 - val_loss: 0.4458 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 165/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.1724 - acc: 0.9325 - val_loss: 0.4486 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 166/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.1725 - acc: 0.9301 - val_loss: 0.4495 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 167/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.1718 - acc: 0.9313 - val_loss: 0.4496 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 168/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.1717 - acc: 0.9313 - val_loss: 0.4493 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 169/250\n",
      "844/844 [==============================] - 0s 23us/step - loss: 0.1721 - acc: 0.9313 - val_loss: 0.4480 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 170/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.1720 - acc: 0.9325 - val_loss: 0.4485 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 171/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.1713 - acc: 0.9336 - val_loss: 0.4494 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 172/250\n",
      "844/844 [==============================] - 0s 24us/step - loss: 0.1716 - acc: 0.9325 - val_loss: 0.4517 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 173/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.1716 - acc: 0.9325 - val_loss: 0.4488 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 174/250\n",
      "844/844 [==============================] - 0s 31us/step - loss: 0.1714 - acc: 0.9325 - val_loss: 0.4492 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 175/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.1714 - acc: 0.9313 - val_loss: 0.4497 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 176/250\n",
      "844/844 [==============================] - 0s 31us/step - loss: 0.1714 - acc: 0.9325 - val_loss: 0.4508 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 177/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.1712 - acc: 0.9336 - val_loss: 0.4511 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 178/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.1716 - acc: 0.9313 - val_loss: 0.4504 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 179/250\n",
      "844/844 [==============================] - ETA: 0s - loss: 0.1644 - acc: 0.9500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - 0s 32us/step - loss: 0.1713 - acc: 0.9336 - val_loss: 0.4509 - val_acc: 0.9052\n",
      "Epoch 180/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.1715 - acc: 0.9325 - val_loss: 0.4518 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 181/250\n",
      "844/844 [==============================] - 0s 24us/step - loss: 0.1713 - acc: 0.9313 - val_loss: 0.4533 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 182/250\n",
      "844/844 [==============================] - 0s 24us/step - loss: 0.1713 - acc: 0.9336 - val_loss: 0.4519 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 183/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.1712 - acc: 0.9325 - val_loss: 0.4487 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 184/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.1717 - acc: 0.9313 - val_loss: 0.4500 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 185/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.1711 - acc: 0.9336 - val_loss: 0.4511 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 186/250\n",
      "844/844 [==============================] - 0s 23us/step - loss: 0.1714 - acc: 0.9313 - val_loss: 0.4512 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 187/250\n",
      "844/844 [==============================] - 0s 24us/step - loss: 0.1713 - acc: 0.9325 - val_loss: 0.4498 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 188/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.1713 - acc: 0.9325 - val_loss: 0.4506 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 189/250\n",
      "844/844 [==============================] - 0s 24us/step - loss: 0.1710 - acc: 0.9301 - val_loss: 0.4517 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 190/250\n",
      "844/844 [==============================] - 0s 24us/step - loss: 0.1715 - acc: 0.9289 - val_loss: 0.4538 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 191/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.1712 - acc: 0.9313 - val_loss: 0.4504 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 192/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.1706 - acc: 0.9325 - val_loss: 0.4511 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 193/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.1711 - acc: 0.9325 - val_loss: 0.4534 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 194/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.1705 - acc: 0.9325 - val_loss: 0.4536 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 195/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.1708 - acc: 0.9325 - val_loss: 0.4530 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 196/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.1710 - acc: 0.9301 - val_loss: 0.4541 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 197/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.1709 - acc: 0.9301 - val_loss: 0.4517 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 198/250\n",
      "844/844 [==============================] - 0s 33us/step - loss: 0.1710 - acc: 0.9348 - val_loss: 0.4499 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 199/250\n",
      "844/844 [==============================] - 0s 33us/step - loss: 0.1704 - acc: 0.9325 - val_loss: 0.4520 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 200/250\n",
      "844/844 [==============================] - 0s 31us/step - loss: 0.1709 - acc: 0.9325 - val_loss: 0.4516 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 201/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.1706 - acc: 0.9313 - val_loss: 0.4502 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 202/250\n",
      "844/844 [==============================] - 0s 32us/step - loss: 0.1707 - acc: 0.9301 - val_loss: 0.4529 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 203/250\n",
      "844/844 [==============================] - 0s 37us/step - loss: 0.1709 - acc: 0.9325 - val_loss: 0.4498 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 204/250\n",
      "844/844 [==============================] - 0s 32us/step - loss: 0.1703 - acc: 0.9325 - val_loss: 0.4520 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 205/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.1708 - acc: 0.9325 - val_loss: 0.4509 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 206/250\n",
      "844/844 [==============================] - 0s 38us/step - loss: 0.1709 - acc: 0.9325 - val_loss: 0.4519 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 207/250\n",
      "844/844 [==============================] - 0s 34us/step - loss: 0.1708 - acc: 0.9348 - val_loss: 0.4501 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 208/250\n",
      "844/844 [==============================] - 0s 32us/step - loss: 0.1708 - acc: 0.9313 - val_loss: 0.4504 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 209/250\n",
      "844/844 [==============================] - 0s 35us/step - loss: 0.1704 - acc: 0.9313 - val_loss: 0.4545 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 210/250\n",
      "844/844 [==============================] - 0s 36us/step - loss: 0.1705 - acc: 0.9325 - val_loss: 0.4509 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 211/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.1703 - acc: 0.9313 - val_loss: 0.4523 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 212/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.1703 - acc: 0.9313 - val_loss: 0.4539 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 213/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.1700 - acc: 0.9313 - val_loss: 0.4521 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 214/250\n",
      "844/844 [==============================] - 0s 30us/step - loss: 0.1704 - acc: 0.9336 - val_loss: 0.4513 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 215/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.1706 - acc: 0.9313 - val_loss: 0.4501 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 216/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.1704 - acc: 0.9325 - val_loss: 0.4534 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 217/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.1705 - acc: 0.9336 - val_loss: 0.4515 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 218/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.1705 - acc: 0.9313 - val_loss: 0.4513 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 219/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.1697 - acc: 0.9336 - val_loss: 0.4526 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 220/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.1701 - acc: 0.9313 - val_loss: 0.4518 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 221/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.1705 - acc: 0.9301 - val_loss: 0.4529 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 222/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.1698 - acc: 0.9325 - val_loss: 0.4536 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 223/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.1705 - acc: 0.9325 - val_loss: 0.4547 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 224/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.1700 - acc: 0.9325 - val_loss: 0.4530 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 225/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.1703 - acc: 0.9325 - val_loss: 0.4505 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 226/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.1701 - acc: 0.9325 - val_loss: 0.4539 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 227/250\n",
      "844/844 [==============================] - 0s 32us/step - loss: 0.1706 - acc: 0.9289 - val_loss: 0.4524 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 228/250\n",
      "844/844 [==============================] - 0s 26us/step - loss: 0.1702 - acc: 0.9313 - val_loss: 0.4533 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 229/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.1701 - acc: 0.9336 - val_loss: 0.4515 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 230/250\n",
      "844/844 [==============================] - 0s 29us/step - loss: 0.1698 - acc: 0.9313 - val_loss: 0.4507 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 231/250\n",
      "844/844 [==============================] - 0s 27us/step - loss: 0.1701 - acc: 0.9301 - val_loss: 0.4549 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 232/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.1699 - acc: 0.9313 - val_loss: 0.4540 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 233/250\n",
      "844/844 [==============================] - 0s 32us/step - loss: 0.1703 - acc: 0.9325 - val_loss: 0.4545 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 234/250\n",
      "844/844 [==============================] - 0s 28us/step - loss: 0.1699 - acc: 0.9325 - val_loss: 0.4514 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 235/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.1699 - acc: 0.9313 - val_loss: 0.4522 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 236/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.1695 - acc: 0.9313 - val_loss: 0.4532 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 237/250\n",
      "844/844 [==============================] - 0s 25us/step - loss: 0.1699 - acc: 0.9301 - val_loss: 0.4539 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 238/250\n",
      "844/844 [==============================] - 0s 32us/step - loss: 0.1697 - acc: 0.9313 - val_loss: 0.4513 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 239/250\n",
      "844/844 [==============================] - 0s 35us/step - loss: 0.1696 - acc: 0.9336 - val_loss: 0.4529 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 240/250\n",
      "844/844 [==============================] - 0s 38us/step - loss: 0.1697 - acc: 0.9313 - val_loss: 0.4536 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 241/250\n",
      "844/844 [==============================] - 0s 37us/step - loss: 0.1694 - acc: 0.9325 - val_loss: 0.4507 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 242/250\n",
      "844/844 [==============================] - 0s 34us/step - loss: 0.1691 - acc: 0.9336 - val_loss: 0.4522 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 243/250\n",
      "844/844 [==============================] - 0s 31us/step - loss: 0.1693 - acc: 0.9313 - val_loss: 0.4544 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 244/250\n",
      "844/844 [==============================] - 0s 35us/step - loss: 0.1692 - acc: 0.9325 - val_loss: 0.4524 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 245/250\n",
      "844/844 [==============================] - 0s 34us/step - loss: 0.1695 - acc: 0.9325 - val_loss: 0.4519 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 246/250\n",
      "844/844 [==============================] - 0s 33us/step - loss: 0.1696 - acc: 0.9325 - val_loss: 0.4521 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 247/250\n",
      "844/844 [==============================] - 0s 32us/step - loss: 0.1692 - acc: 0.9313 - val_loss: 0.4552 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 248/250\n",
      "844/844 [==============================] - 0s 34us/step - loss: 0.1697 - acc: 0.9313 - val_loss: 0.4528 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 249/250\n",
      "844/844 [==============================] - 0s 34us/step - loss: 0.1695 - acc: 0.9348 - val_loss: 0.4523 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 250/250\n",
      "844/844 [==============================] - 0s 38us/step - loss: 0.1694 - acc: 0.9325 - val_loss: 0.4525 - val_acc: 0.9052\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "211/211 [==============================] - 0s 48us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.45250630576463674, 0.9052132707071531]"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_pca, train_y, epochs=250, batch_size=80, validation_split=.2)\n",
    "best_val = model.evaluate(train_pca[-num_validation:], train_y[-num_validation:])\n",
    "best_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 791 samples, validate on 264 samples\n",
      "Epoch 1/20\n",
      "791/791 [==============================] - 0s 19us/step - loss: 0.1519 - acc: 0.9558 - val_loss: 0.5183 - val_acc: 0.8977\n",
      "Epoch 2/20\n",
      "791/791 [==============================] - 0s 19us/step - loss: 0.1402 - acc: 0.9532 - val_loss: 0.5204 - val_acc: 0.8977\n",
      "Epoch 3/20\n",
      "791/791 [==============================] - 0s 24us/step - loss: 0.1570 - acc: 0.9545 - val_loss: 0.5212 - val_acc: 0.8977\n",
      "Epoch 4/20\n",
      "791/791 [==============================] - 0s 27us/step - loss: 0.1474 - acc: 0.9583 - val_loss: 0.5221 - val_acc: 0.9015\n",
      "Epoch 5/20\n",
      "791/791 [==============================] - 0s 28us/step - loss: 0.1500 - acc: 0.9494 - val_loss: 0.5230 - val_acc: 0.9015\n",
      "Epoch 6/20\n",
      "791/791 [==============================] - 0s 27us/step - loss: 0.1426 - acc: 0.9558 - val_loss: 0.5228 - val_acc: 0.9015\n",
      "Epoch 7/20\n",
      "791/791 [==============================] - 0s 24us/step - loss: 0.1491 - acc: 0.9621 - val_loss: 0.5232 - val_acc: 0.9015\n",
      "Epoch 8/20\n",
      "791/791 [==============================] - 0s 23us/step - loss: 0.1850 - acc: 0.9406 - val_loss: 0.5237 - val_acc: 0.9015\n",
      "Epoch 9/20\n",
      "791/791 [==============================] - 0s 23us/step - loss: 0.1590 - acc: 0.9570 - val_loss: 0.5247 - val_acc: 0.9015\n",
      "Epoch 10/20\n",
      "791/791 [==============================] - 0s 22us/step - loss: 0.1638 - acc: 0.9545 - val_loss: 0.5266 - val_acc: 0.8939\n",
      "Epoch 11/20\n",
      "791/791 [==============================] - 0s 22us/step - loss: 0.1730 - acc: 0.9494 - val_loss: 0.5293 - val_acc: 0.8902\n",
      "Epoch 12/20\n",
      "791/791 [==============================] - 0s 24us/step - loss: 0.1397 - acc: 0.9545 - val_loss: 0.5298 - val_acc: 0.8902\n",
      "Epoch 13/20\n",
      "791/791 [==============================] - 0s 23us/step - loss: 0.1284 - acc: 0.9633 - val_loss: 0.5306 - val_acc: 0.8902\n",
      "Epoch 14/20\n",
      "791/791 [==============================] - 0s 21us/step - loss: 0.1603 - acc: 0.9456 - val_loss: 0.5312 - val_acc: 0.8902\n",
      "Epoch 15/20\n",
      "791/791 [==============================] - 0s 22us/step - loss: 0.1436 - acc: 0.9570 - val_loss: 0.5305 - val_acc: 0.8902\n",
      "Epoch 16/20\n",
      "791/791 [==============================] - 0s 24us/step - loss: 0.1472 - acc: 0.9583 - val_loss: 0.5295 - val_acc: 0.8902\n",
      "Epoch 17/20\n",
      "791/791 [==============================] - 0s 28us/step - loss: 0.1587 - acc: 0.9456 - val_loss: 0.5294 - val_acc: 0.8902\n",
      "Epoch 18/20\n",
      "791/791 [==============================] - 0s 24us/step - loss: 0.1586 - acc: 0.9494 - val_loss: 0.5297 - val_acc: 0.8939\n",
      "Epoch 19/20\n",
      "791/791 [==============================] - 0s 26us/step - loss: 0.1534 - acc: 0.9482 - val_loss: 0.5306 - val_acc: 0.8939\n",
      "Epoch 20/20\n",
      "791/791 [==============================] - 0s 25us/step - loss: 0.1703 - acc: 0.9507 - val_loss: 0.5316 - val_acc: 0.8939\n",
      "211/211 [==============================] - 0s 90us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Train on 791 samples, validate on 264 samples\n",
      "Epoch 1/20\n",
      "791/791 [==============================] - 3s 4ms/step - loss: 0.1490 - acc: 0.9570 - val_loss: 0.5243 - val_acc: 0.8939\n",
      "Epoch 2/20\n",
      "791/791 [==============================] - 0s 27us/step - loss: 0.1613 - acc: 0.9494 - val_loss: 0.5268 - val_acc: 0.8939\n",
      "Epoch 3/20\n",
      "791/791 [==============================] - 0s 24us/step - loss: 0.1513 - acc: 0.9532 - val_loss: 0.5250 - val_acc: 0.8939\n",
      "Epoch 4/20\n",
      "791/791 [==============================] - 0s 22us/step - loss: 0.1628 - acc: 0.9494 - val_loss: 0.5217 - val_acc: 0.8939\n",
      "Epoch 5/20\n",
      "791/791 [==============================] - 0s 26us/step - loss: 0.1509 - acc: 0.9482 - val_loss: 0.5192 - val_acc: 0.9015\n",
      "Epoch 6/20\n",
      "791/791 [==============================] - 0s 23us/step - loss: 0.1552 - acc: 0.9532 - val_loss: 0.5184 - val_acc: 0.9015\n",
      "Epoch 7/20\n",
      "791/791 [==============================] - 0s 23us/step - loss: 0.1439 - acc: 0.9570 - val_loss: 0.5176 - val_acc: 0.9015\n",
      "Epoch 8/20\n",
      "791/791 [==============================] - 0s 25us/step - loss: 0.1782 - acc: 0.9558 - val_loss: 0.5168 - val_acc: 0.9015\n",
      "Epoch 9/20\n",
      "791/791 [==============================] - 0s 22us/step - loss: 0.1657 - acc: 0.9545 - val_loss: 0.5171 - val_acc: 0.8939\n",
      "Epoch 10/20\n",
      "791/791 [==============================] - 0s 19us/step - loss: 0.1494 - acc: 0.9507 - val_loss: 0.5173 - val_acc: 0.8977\n",
      "Epoch 11/20\n",
      "791/791 [==============================] - 0s 19us/step - loss: 0.1333 - acc: 0.9608 - val_loss: 0.5170 - val_acc: 0.8977\n",
      "Epoch 12/20\n",
      "791/791 [==============================] - 0s 17us/step - loss: 0.1280 - acc: 0.9633 - val_loss: 0.5178 - val_acc: 0.8977\n",
      "Epoch 13/20\n",
      "791/791 [==============================] - 0s 21us/step - loss: 0.1359 - acc: 0.9558 - val_loss: 0.5200 - val_acc: 0.8977\n",
      "Epoch 14/20\n",
      "791/791 [==============================] - 0s 23us/step - loss: 0.1414 - acc: 0.9633 - val_loss: 0.5229 - val_acc: 0.8977\n",
      "Epoch 15/20\n",
      "791/791 [==============================] - 0s 23us/step - loss: 0.1328 - acc: 0.9583 - val_loss: 0.5271 - val_acc: 0.9015\n",
      "Epoch 16/20\n",
      "791/791 [==============================] - 0s 20us/step - loss: 0.1349 - acc: 0.9595 - val_loss: 0.5305 - val_acc: 0.9015\n",
      "Epoch 17/20\n",
      "791/791 [==============================] - 0s 22us/step - loss: 0.1228 - acc: 0.9659 - val_loss: 0.5343 - val_acc: 0.8977\n",
      "Epoch 18/20\n",
      "791/791 [==============================] - 0s 20us/step - loss: 0.1490 - acc: 0.9532 - val_loss: 0.5382 - val_acc: 0.9015\n",
      "Epoch 19/20\n",
      "791/791 [==============================] - 0s 22us/step - loss: 0.1616 - acc: 0.9532 - val_loss: 0.5417 - val_acc: 0.9015\n",
      "Epoch 20/20\n",
      "791/791 [==============================] - 0s 21us/step - loss: 0.1488 - acc: 0.9456 - val_loss: 0.5446 - val_acc: 0.9015\n",
      "211/211 [==============================] - 0s 74us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Train on 791 samples, validate on 264 samples\n",
      "Epoch 1/20\n",
      "791/791 [==============================] - 3s 3ms/step - loss: 0.1594 - acc: 0.9494 - val_loss: 0.5185 - val_acc: 0.9015\n",
      "Epoch 2/20\n",
      "791/791 [==============================] - 0s 24us/step - loss: 0.1407 - acc: 0.9583 - val_loss: 0.5220 - val_acc: 0.8977\n",
      "Epoch 3/20\n",
      "791/791 [==============================] - 0s 21us/step - loss: 0.1448 - acc: 0.9507 - val_loss: 0.5282 - val_acc: 0.8939\n",
      "Epoch 4/20\n",
      "791/791 [==============================] - 0s 29us/step - loss: 0.1605 - acc: 0.9507 - val_loss: 0.5315 - val_acc: 0.8939\n",
      "Epoch 5/20\n",
      "791/791 [==============================] - 0s 23us/step - loss: 0.1551 - acc: 0.9545 - val_loss: 0.5336 - val_acc: 0.8902\n",
      "Epoch 6/20\n",
      "791/791 [==============================] - 0s 23us/step - loss: 0.1313 - acc: 0.9646 - val_loss: 0.5369 - val_acc: 0.8939\n",
      "Epoch 7/20\n",
      "791/791 [==============================] - 0s 24us/step - loss: 0.1302 - acc: 0.9659 - val_loss: 0.5403 - val_acc: 0.8902\n",
      "Epoch 8/20\n",
      "791/791 [==============================] - 0s 21us/step - loss: 0.1495 - acc: 0.9583 - val_loss: 0.5440 - val_acc: 0.8902\n",
      "Epoch 9/20\n",
      "791/791 [==============================] - 0s 21us/step - loss: 0.1671 - acc: 0.9520 - val_loss: 0.5468 - val_acc: 0.8939\n",
      "Epoch 10/20\n",
      "791/791 [==============================] - 0s 24us/step - loss: 0.1549 - acc: 0.9494 - val_loss: 0.5494 - val_acc: 0.8939\n",
      "Epoch 11/20\n",
      "791/791 [==============================] - 0s 21us/step - loss: 0.1525 - acc: 0.9532 - val_loss: 0.5538 - val_acc: 0.8939\n",
      "Epoch 12/20\n",
      "791/791 [==============================] - 0s 22us/step - loss: 0.1559 - acc: 0.9532 - val_loss: 0.5566 - val_acc: 0.8939\n",
      "Epoch 13/20\n",
      "791/791 [==============================] - 0s 24us/step - loss: 0.1545 - acc: 0.9558 - val_loss: 0.5604 - val_acc: 0.8864\n",
      "Epoch 14/20\n",
      "791/791 [==============================] - 0s 22us/step - loss: 0.1509 - acc: 0.9570 - val_loss: 0.5641 - val_acc: 0.8902\n",
      "Epoch 15/20\n",
      "791/791 [==============================] - 0s 22us/step - loss: 0.1494 - acc: 0.9494 - val_loss: 0.5674 - val_acc: 0.8902\n",
      "Epoch 16/20\n",
      "791/791 [==============================] - 0s 22us/step - loss: 0.1448 - acc: 0.9545 - val_loss: 0.5689 - val_acc: 0.8977\n",
      "Epoch 17/20\n",
      "791/791 [==============================] - 0s 23us/step - loss: 0.1551 - acc: 0.9520 - val_loss: 0.5700 - val_acc: 0.8977\n",
      "Epoch 18/20\n",
      "791/791 [==============================] - 0s 18us/step - loss: 0.1510 - acc: 0.9494 - val_loss: 0.5708 - val_acc: 0.8939\n",
      "Epoch 19/20\n",
      "791/791 [==============================] - 0s 19us/step - loss: 0.1377 - acc: 0.9621 - val_loss: 0.5714 - val_acc: 0.8939\n",
      "Epoch 20/20\n",
      "791/791 [==============================] - 0s 24us/step - loss: 0.1390 - acc: 0.9595 - val_loss: 0.5714 - val_acc: 0.8977\n",
      "211/211 [==============================] - 0s 86us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Train on 791 samples, validate on 264 samples\n",
      "Epoch 1/20\n",
      "791/791 [==============================] - 3s 3ms/step - loss: 0.1369 - acc: 0.9520 - val_loss: 0.5201 - val_acc: 0.9015\n",
      "Epoch 2/20\n",
      "791/791 [==============================] - 0s 23us/step - loss: 0.1452 - acc: 0.9583 - val_loss: 0.5316 - val_acc: 0.8939\n",
      "Epoch 3/20\n",
      "791/791 [==============================] - 0s 22us/step - loss: 0.1776 - acc: 0.9532 - val_loss: 0.5440 - val_acc: 0.8939\n",
      "Epoch 4/20\n",
      "791/791 [==============================] - 0s 26us/step - loss: 0.1589 - acc: 0.9545 - val_loss: 0.5526 - val_acc: 0.8939\n",
      "Epoch 5/20\n",
      "791/791 [==============================] - 0s 24us/step - loss: 0.1446 - acc: 0.9507 - val_loss: 0.5582 - val_acc: 0.8939\n",
      "Epoch 6/20\n",
      "791/791 [==============================] - 0s 23us/step - loss: 0.1637 - acc: 0.9545 - val_loss: 0.5616 - val_acc: 0.8939\n",
      "Epoch 7/20\n",
      "791/791 [==============================] - 0s 27us/step - loss: 0.1544 - acc: 0.9507 - val_loss: 0.5632 - val_acc: 0.8939\n",
      "Epoch 8/20\n",
      "791/791 [==============================] - 0s 22us/step - loss: 0.1527 - acc: 0.9507 - val_loss: 0.5643 - val_acc: 0.8939\n",
      "Epoch 9/20\n",
      "791/791 [==============================] - 0s 22us/step - loss: 0.1648 - acc: 0.9456 - val_loss: 0.5637 - val_acc: 0.8977\n",
      "Epoch 10/20\n",
      "791/791 [==============================] - 0s 22us/step - loss: 0.1627 - acc: 0.9494 - val_loss: 0.5615 - val_acc: 0.8977\n",
      "Epoch 11/20\n",
      "791/791 [==============================] - 0s 22us/step - loss: 0.1509 - acc: 0.9558 - val_loss: 0.5604 - val_acc: 0.8977\n",
      "Epoch 12/20\n",
      "791/791 [==============================] - 0s 25us/step - loss: 0.1526 - acc: 0.9608 - val_loss: 0.5603 - val_acc: 0.8977\n",
      "Epoch 13/20\n",
      "791/791 [==============================] - 0s 23us/step - loss: 0.1510 - acc: 0.9583 - val_loss: 0.5604 - val_acc: 0.8977\n",
      "Epoch 14/20\n",
      "791/791 [==============================] - 0s 23us/step - loss: 0.1477 - acc: 0.9570 - val_loss: 0.5609 - val_acc: 0.8977\n",
      "Epoch 15/20\n",
      "791/791 [==============================] - 0s 23us/step - loss: 0.1417 - acc: 0.9558 - val_loss: 0.5606 - val_acc: 0.8977\n",
      "Epoch 16/20\n",
      "791/791 [==============================] - 0s 20us/step - loss: 0.1512 - acc: 0.9482 - val_loss: 0.5621 - val_acc: 0.8977\n",
      "Epoch 17/20\n",
      "791/791 [==============================] - 0s 23us/step - loss: 0.1435 - acc: 0.9558 - val_loss: 0.5637 - val_acc: 0.8977\n",
      "Epoch 18/20\n",
      "791/791 [==============================] - 0s 20us/step - loss: 0.1353 - acc: 0.9608 - val_loss: 0.5653 - val_acc: 0.8939\n",
      "Epoch 19/20\n",
      "791/791 [==============================] - 0s 22us/step - loss: 0.1654 - acc: 0.9456 - val_loss: 0.5661 - val_acc: 0.8939\n",
      "Epoch 20/20\n",
      "791/791 [==============================] - 0s 23us/step - loss: 0.1439 - acc: 0.9608 - val_loss: 0.5664 - val_acc: 0.8977\n",
      "211/211 [==============================] - 0s 76us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Train on 791 samples, validate on 264 samples\n",
      "Epoch 1/20\n",
      "791/791 [==============================] - 3s 4ms/step - loss: 0.1320 - acc: 0.9545 - val_loss: 0.5234 - val_acc: 0.8977\n",
      "Epoch 2/20\n",
      "791/791 [==============================] - 0s 22us/step - loss: 0.1698 - acc: 0.9406 - val_loss: 0.5286 - val_acc: 0.8977\n",
      "Epoch 3/20\n",
      "791/791 [==============================] - 0s 20us/step - loss: 0.1537 - acc: 0.9595 - val_loss: 0.5290 - val_acc: 0.8977\n",
      "Epoch 4/20\n",
      "791/791 [==============================] - 0s 25us/step - loss: 0.1605 - acc: 0.9482 - val_loss: 0.5253 - val_acc: 0.8977\n",
      "Epoch 5/20\n",
      "791/791 [==============================] - 0s 20us/step - loss: 0.1626 - acc: 0.9507 - val_loss: 0.5235 - val_acc: 0.8977\n",
      "Epoch 6/20\n",
      "791/791 [==============================] - 0s 25us/step - loss: 0.1432 - acc: 0.9482 - val_loss: 0.5221 - val_acc: 0.9015\n",
      "Epoch 7/20\n",
      "791/791 [==============================] - 0s 20us/step - loss: 0.1280 - acc: 0.9633 - val_loss: 0.5212 - val_acc: 0.8977\n",
      "Epoch 8/20\n",
      "791/791 [==============================] - 0s 25us/step - loss: 0.1524 - acc: 0.9621 - val_loss: 0.5214 - val_acc: 0.9015\n",
      "Epoch 9/20\n",
      "791/791 [==============================] - 0s 22us/step - loss: 0.1350 - acc: 0.9659 - val_loss: 0.5222 - val_acc: 0.9015\n",
      "Epoch 10/20\n",
      "791/791 [==============================] - 0s 22us/step - loss: 0.1570 - acc: 0.9507 - val_loss: 0.5235 - val_acc: 0.9015\n",
      "Epoch 11/20\n",
      "791/791 [==============================] - 0s 22us/step - loss: 0.1448 - acc: 0.9595 - val_loss: 0.5245 - val_acc: 0.9015\n",
      "Epoch 12/20\n",
      "791/791 [==============================] - 0s 24us/step - loss: 0.1344 - acc: 0.9621 - val_loss: 0.5259 - val_acc: 0.9015\n",
      "Epoch 13/20\n",
      "791/791 [==============================] - 0s 22us/step - loss: 0.1533 - acc: 0.9507 - val_loss: 0.5262 - val_acc: 0.8977\n",
      "Epoch 14/20\n",
      "791/791 [==============================] - 0s 24us/step - loss: 0.1446 - acc: 0.9558 - val_loss: 0.5274 - val_acc: 0.8977\n",
      "Epoch 15/20\n",
      "791/791 [==============================] - 0s 21us/step - loss: 0.1766 - acc: 0.9418 - val_loss: 0.5274 - val_acc: 0.8977\n",
      "Epoch 16/20\n",
      "791/791 [==============================] - 0s 22us/step - loss: 0.1446 - acc: 0.9558 - val_loss: 0.5281 - val_acc: 0.8977\n",
      "Epoch 17/20\n",
      "791/791 [==============================] - 0s 20us/step - loss: 0.1379 - acc: 0.9583 - val_loss: 0.5289 - val_acc: 0.8977\n",
      "Epoch 18/20\n",
      "791/791 [==============================] - 0s 21us/step - loss: 0.1290 - acc: 0.9583 - val_loss: 0.5293 - val_acc: 0.9015\n",
      "Epoch 19/20\n",
      "791/791 [==============================] - 0s 23us/step - loss: 0.1454 - acc: 0.9583 - val_loss: 0.5296 - val_acc: 0.9015\n",
      "Epoch 20/20\n",
      "791/791 [==============================] - 0s 24us/step - loss: 0.1801 - acc: 0.9431 - val_loss: 0.5301 - val_acc: 0.9015\n",
      "211/211 [==============================] - 0s 76us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(5):\n",
    "    model_copy = keras.models.clone_model(model)\n",
    "    model_copy.set_weights(model.get_weights())\n",
    "    model.fit(train_pca, train_y, epochs=20, batch_size=1000, validation_split=.25)\n",
    "    val_score = model.evaluate(train_pca[-int(np.ceil((len(train_matrix)*.2))):], train_y[-int(np.ceil((len(train_matrix)*.2))):])[1]\n",
    "    if val_score < best_val:\n",
    "        model = model_copy\n",
    "        model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "    else:\n",
    "        best_val = val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(train_pca, to_categorical(train_y, num_classes = 2), epochs=1200, batch_size=80, validation_split=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 0s 43us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2846901022709941, 0.8862559227581838]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(train_pca[-num_validation:], train_y[-num_validation:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-20700356566b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_train_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'new_train' is not defined"
     ]
    }
   ],
   "source": [
    "model.evaluate(new_train, new_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_31 to have shape (1,) but got array with shape (2,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-a961ddb8f0fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_pca\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1002\u001b[0m                                    \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m                                    \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                    steps=steps)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1766\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1768\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1769\u001b[0m         \u001b[1;31m# Prepare inputs, delegate logic to `_test_loop`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1770\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m   1478\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1480\u001b[0;31m                                     exception_prefix='target')\n\u001b[0m\u001b[1;32m   1481\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1482\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    121\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_31 to have shape (1,) but got array with shape (2,)"
     ]
    }
   ],
   "source": [
    "model.evaluate(train_pca[-int(np.ceil((len(train_matrix)*.2))):], to_categorical(train_y[-int(np.ceil((len(train_matrix)*.2))):], num_classes = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1055/1055 [==============================] - 0s 38us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.7161996170242815, 0.8834123214839195]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(train_pca, to_categorical(train_y, num_classes = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(np.ceil((len(train_matrix)*.2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataframe = pd.read_csv(\"../data/chemstest.csv\", sep=',')\n",
    "test_matrix = pd.DataFrame.as_matrix(test_dataframe.iloc[:,:-1])\n",
    "test_pca = pca.transform(test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict_classes(test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "1\n",
      "-1\n",
      "1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "for num in test_predictions[:,0]:\n",
    "    print((num*2) - 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
