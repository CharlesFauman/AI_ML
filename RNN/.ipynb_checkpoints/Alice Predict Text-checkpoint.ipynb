{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  144412\n",
      "Total Vocab:  47\n"
     ]
    }
   ],
   "source": [
    "# load ascii text and covert to lowercase\n",
    "filename = \"wonderland.txt\"\n",
    "raw_text = open(filename, mode = 'r', encoding = 'utf8').read()\n",
    "raw_text = raw_text.lower()\n",
    "# create mapping of unique chars to integers\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "# summarize the loaded data\n",
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print (\"Total Characters: \", n_chars)\n",
    "print (\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  144312\n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    seq_in = raw_text[i:i + seq_length]\n",
    "    seq_out = raw_text[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns)\n",
    "# reshape X to be [samples, time steps, features]\n",
    "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "144256/144312 [============================>.] - ETA: 0s - loss: 1.8957Epoch 00001: loss improved from inf to 1.89571, saving model to weights-improvement-01-1.8957.hdf5\n",
      "144312/144312 [==============================] - 431s 3ms/step - loss: 1.8957\n",
      "Epoch 2/10\n",
      "144256/144312 [============================>.] - ETA: 0s - loss: 1.8755Epoch 00002: loss improved from 1.89571 to 1.87549, saving model to weights-improvement-02-1.8755.hdf5\n",
      "144312/144312 [==============================] - 434s 3ms/step - loss: 1.8755\n",
      "Epoch 3/10\n",
      "144256/144312 [============================>.] - ETA: 0s - loss: 1.8519Epoch 00003: loss improved from 1.87549 to 1.85186, saving model to weights-improvement-03-1.8519.hdf5\n",
      "144312/144312 [==============================] - 434s 3ms/step - loss: 1.8519\n",
      "Epoch 4/10\n",
      "144256/144312 [============================>.] - ETA: 0s - loss: 1.8323Epoch 00004: loss improved from 1.85186 to 1.83233, saving model to weights-improvement-04-1.8323.hdf5\n",
      "144312/144312 [==============================] - 426s 3ms/step - loss: 1.8323\n",
      "Epoch 5/10\n",
      "144256/144312 [============================>.] - ETA: 0s - loss: 1.8136Epoch 00005: loss improved from 1.83233 to 1.81362, saving model to weights-improvement-05-1.8136.hdf5\n",
      "144312/144312 [==============================] - 446s 3ms/step - loss: 1.8136\n",
      "Epoch 6/10\n",
      "144256/144312 [============================>.] - ETA: 0s - loss: 1.7958Epoch 00006: loss improved from 1.81362 to 1.79584, saving model to weights-improvement-06-1.7958.hdf5\n",
      "144312/144312 [==============================] - 461s 3ms/step - loss: 1.7958\n",
      "Epoch 7/10\n",
      "144256/144312 [============================>.] - ETA: 0s - loss: 1.7767Epoch 00007: loss improved from 1.79584 to 1.77662, saving model to weights-improvement-07-1.7766.hdf5\n",
      "144312/144312 [==============================] - 436s 3ms/step - loss: 1.7766\n",
      "Epoch 8/10\n",
      "144256/144312 [============================>.] - ETA: 0s - loss: 1.7595Epoch 00008: loss improved from 1.77662 to 1.75938, saving model to weights-improvement-08-1.7594.hdf5\n",
      "144312/144312 [==============================] - 433s 3ms/step - loss: 1.7594\n",
      "Epoch 9/10\n",
      "144256/144312 [============================>.] - ETA: 0s - loss: 1.7458Epoch 00009: loss improved from 1.75938 to 1.74579, saving model to weights-improvement-09-1.7458.hdf5\n",
      "144312/144312 [==============================] - 441s 3ms/step - loss: 1.7458\n",
      "Epoch 10/10\n",
      "144256/144312 [============================>.] - ETA: 0s - loss: 1.7338Epoch 00010: loss improved from 1.74579 to 1.73379, saving model to weights-improvement-10-1.7338.hdf5\n",
      "144312/144312 [==============================] - 437s 3ms/step - loss: 1.7338\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2be3a1a8470>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "# fit the model\n",
    "model.fit(X, y, epochs=10, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the network weights\n",
    "filename = \"weights-improvement-19-1.9435.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"                                                                                                      \"\n"
     ]
    }
   ],
   "source": [
    "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" xious look at the\n",
      "queen, who was reading the list of singers.\n",
      "\n",
      "‘you may go,’ said the king, and the  \"\n",
      "\n",
      "white rabbit with the sas oo the wind she had been tan oh thet would hev fead  and the west ooon oatelt aloug thet sae in whe pore of the card wishe all the was oo the court,\n",
      "and the whste thieg eead oo ko tite toine the was oot in the tioe, ‘hh a loer turt then i’  a danterf tour a ganter way in the wey, the hoestens hod tou do wou would the lotent toie a aretse sf the coerssr. and she was not io tie lint ano thet sar dnwn at the would har ane the courd. and then the was tointing ablut to the kooe th the shieg of the haad.\n",
      "\n",
      "‘ihwe your havesed if that ’ou taal the weit to io the seit,’ the macco iareile ‘irt ooth then it tas aooe ano the sooel of the coumh. and the was so alice io the tine. \n",
      "‘hh mn hase to toee,’ said the cat, ‘in you taae thet would be toute the would tely wou doonst ’huh the doemens!’\n",
      "\n",
      "‘hnt to tha mors ofees oo your aliien ’ the said to herself, ‘oo thet soee oo torn th teen the white rabe thes wou donldn to meve the three oayee bnongrt then it was ali the sas oo hor\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# pick a random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print (\"Seed:\")\n",
    "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "\n",
    "print()\n",
    "\n",
    "# generate characters\n",
    "for i in range(1000):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    print(result , end = \"\")\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print (\"\\nDone.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
